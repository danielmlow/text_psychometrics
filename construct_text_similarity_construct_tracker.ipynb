{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ad9613-67ce-40a3-a207-595bd98e1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q nltk # for catpro\n",
    "# !pip install -q -U pip setuptools wheel\n",
    "# !pip install -q -U 'spacy[apple]' # catpro, change according to device\n",
    "# !python -m spacy download en_core_web_sm #for catpro\n",
    "# !pip install -q deplacy==2.0.5\n",
    "# !pip install -q sentence-transformers==2.2.2\n",
    "# !pip install -q -U ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b161c23-59e0-46d3-8d08-02a0d1d64cbd",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "1. Preprocess document (and construct)\n",
    "- Tokenize into clauses\n",
    "- Tokenize into words, remove stop words, lemmatize : useful for lexicon count as well\n",
    "\n",
    "2. Encode construct:\n",
    "- construct prototype: I want to die\n",
    "- each token: I wish I didn't wake up tomorrow\n",
    "- weighted centroid\n",
    "\n",
    "3. Encode doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214e4d06-30fd-4074-820a-06047e369e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we need to load this here so that preprocessing.embeddings.vectorize runs properly\n",
    "# import torch\n",
    "# import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c966a-d2ae-4ff1-a31f-10e38bfe000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import seaborn as sns\n",
    "import sys\n",
    "# local scripts\n",
    "# from preprocessing import stop_words\n",
    "# from preprocessing import clean\n",
    "# from preprocessing.tokenizer import spacy_tokenizer\n",
    "# from preprocessing.lemmatizer import spacy_lemmatizer\n",
    "# from preprocessing.embeddings import vectorize\n",
    "# import cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddf20e1-7701-4bb2-8262-60c339a5f44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # caution: path[0] is reserved for script path (or '' in REPL)\n",
    "# sys.path.insert(1, './../catpro')\n",
    "\n",
    "# from catpro.text.utils import stop_words\n",
    "# from catpro.text.utils import clean\n",
    "# from catpro.text.utils.tokenizer import spacy_tokenizer\n",
    "# from catpro.text.utils.lemmatizer import spacy_lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86d205d-495e-4fae-84f5-73f02b71b5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = datetime.datetime.utcnow().strftime('%y-%m-%dT%H-%M-%S')\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa30977-c7a5-42ab-8277-15c70c72adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = './../../../data/ctl/input/datasets/'\n",
    "output_dir = './data/'\n",
    "\n",
    "task = 'classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28088c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "run_this = False#True saves, False loads\n",
    "if run_this:\n",
    "    with open(f'./data/input/ctl/ctl_dfs_features_{task}.pkl', 'wb') as f:\n",
    "        pickle.dump(dfs, f) \n",
    "else:\n",
    "\n",
    "    with open(f'./data/input/ctl/ctl_dfs_features_{task}.pkl', 'rb') as f:\n",
    "    \tdfs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59226f1-388a-42a0-800c-cda4e1aa1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "construct_representation = 'lexicon' #(lexicon is good for 'prototypes')\n",
    "doc_representation = 'clauses'\n",
    "embedding_type = 'sentence'\n",
    "embedding_model = 'all-MiniLM-L6-v2'\n",
    "# embedding_package = 'flair'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee638d5-29ce-4f34-a023-c1f8634494e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs['test'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66218389",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.read_csv('./data/input/ctl/X_test_all_with_interaction.csv')\n",
    "X_test_df = X_test_df.iloc[:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fbfc8-7d10-4fa6-9b18-1c108b34442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01059627-6c62-4f40-9279-e5bf6c4d60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dvs_for_prompts = {\n",
    "    \n",
    "#     'isolate':'lonely',\n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cdf4e-a3af-4f3c-b4ab-93aba9b20608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50298f4c-75a3-4ab3-bcfe-434064a7d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approach_embedding_names = [  # lexicon centroid weighted by distance to construct label\n",
    "#    # 'w_w_glove', \n",
    "#     # 'w_c_psychbert',\n",
    "#     # 'w_w_minilm', \n",
    "#     'w_c_minilm',           \n",
    "#     # 'wl_w_minilm',\n",
    "#     # 'wl_c_minilm'\n",
    "# ]\n",
    "    \n",
    "\n",
    "# embedding_name_type = {\n",
    "# #    model_name:embedding_type \n",
    "#     # 'glove': 'word',\n",
    "#     'all-MiniLM-L6-v2': 'sentence',\n",
    "#     # 'all-MiniLM-L6-v2': 'document',\n",
    "#     # 'mnaylor/psychbert-cased': 'document',# need to fix  \n",
    "# }\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc3c09-073f-43a2-84e7-2def481ea55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22c57d-6a74-4cdb-bc71-8b7315aa9bb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "1. spell checker: automatically may create a lot of errors. It works by prividing closest orthographic neighbor to words not in a dictionary pyspellchecker is an option.\n",
    "2. Remove authentification words: TALK, CONNECT, FEEL, BREATHE, HOPELINE, (can be lower case?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4def0-cdef-454d-a2c1-d569c7c6e12b",
   "metadata": {},
   "source": [
    "### TODO: remove words with negation 1-3 words prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa8b73-62cc-4577-95dd-031449a17bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fast: 1 sec every 10 000 messages\n",
    "\n",
    "run_this = False\n",
    "\n",
    "if run_this:\n",
    "    docs =metadata_df['message'].values\n",
    "    # docs = [re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", n) for n in docs] #replace text within parentheses/brackets and parentheses/brackets\n",
    "    # docs = [n.replace('//', '').replace(' .', '.').replace(' ,', ',') for n in docs] \n",
    "    # docs = [n.replace('ampx200b', '').replace('\\n','').replace('\\xa0', '') for n in docs]\n",
    "    docs_clean = [str(n) if str(n)!='nan' else '' for n in docs]\n",
    "    docs_clean = [n.replace('!.', '!').replace('?.', '?').replace('....', '...').replace('...', '... ') for n in docs_clean]\n",
    "    docs_clean = [clean.remove_multiple_spaces(doc) for doc in docs_clean]\n",
    "    metadata_df['docs_clean'] = docs_clean\n",
    "    print('made a difference in', metadata_df[metadata_df['message'] != metadata_df['docs_clean']].shape[0]/metadata_df.shape[0], 'samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028551c2-8853-4fda-b8d8-f358ca98a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_stop_words = ['ca', 'nt','like', \"'\", \"´\", \"n’t\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0cf99-a569-462b-b92b-0b792dce01db",
   "metadata": {},
   "source": [
    "### tokenize documents into words (remove stop words and lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4687139-d7fd-4ffa-9de7-baf87aa2d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_this = False \n",
    "\n",
    "if run_this:\n",
    "    # words: tokenize by words, remove stop words and lemmatize for word-word similarity\n",
    "    docs_clean_w_w = stop_words.remove(list(docs_clean), language = 'en', sws = 'nltk', remove_punct=True, extend_stopwords=more_stop_words)\n",
    "    docs_clean_w_w = [clean.remove_multiple_spaces(doc) for doc in docs_clean_w_w]\n",
    "    docs_clean_w_w = spacy_lemmatizer(docs_clean_w_w, language ='en') #this takes 22s for 5200 docs\n",
    "    df['docs_clean_w_w'] = docs_clean_w_w\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfe266-1d8a-4c52-afb5-6d80b97a1ff8",
   "metadata": {},
   "source": [
    "### Tokenize into clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867604e3-9d18-4026-a5f6-6a4929f30808",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# 15m samples for 38k CTL convos\n",
    "\n",
    "\n",
    "\n",
    "run_this = False\n",
    "\n",
    "\n",
    "if run_this:\n",
    "    # docs_clean_clauses = [clean.remove_multiple_spaces(doc) for doc in docs_clean]\n",
    "    docs_clean_clauses = spacy_tokenizer(docs_clean, \n",
    "                                     language = 'en', model='en_core_web_sm', \n",
    "                                     token = 'clause', # clause tokenization\n",
    "                                     lowercase=False, \n",
    "                                     display_tree = False, \n",
    "                                     remove_punct=True, \n",
    "                                     clause_remove_conj = True)\n",
    "    \n",
    "    \n",
    "    metadata_df['docs_clean_clauses'] = docs_clean_clauses\n",
    "    metadata_df.to_csv(input_dir+f'train10_train_concurrent_metadata_messages_preprocessed_{ts}.csv')\n",
    "else:\n",
    "    metadata_df = pd.read_csv(input_dir+f'train10_train_concurrent_metadata_messages_preprocessed_23-07-20T02-00-58.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09af23f-8c51-49dc-9a9a-6e4dc234c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df[['message','docs_clean_clauses']].iloc[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f97f9-e6e5-48bc-a7cc-6644e762c12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata_df[['message','docs_clean_clauses','docs_clean_w_w']].iloc[::10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2895e3e-dcfe-4fd6-a2ec-a5f46dbba453",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Encode embeddings and compute similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ddbc2-32c0-421b-b0f9-401af18b2ca9",
   "metadata": {},
   "source": [
    "### Construct (Lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078990fa-51c6-42ad-9034-f5a0d06cf9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load risk factor and encode\n",
    "\n",
    "# input_dir_lexicons = './data/input/lexicons/'\n",
    "# # lexicon = pd.read_csv(input_dir_catpro+'lexicons/suicidal_thoughts_and_behaviors/suicide_risk_lexicon_thesauri_questionnaires_23-03-16T19-35-06.csv', index_col = 0)\n",
    "# import json\n",
    "\n",
    "# with open(input_dir_lexicons+'suicide_risk_lexicon_thesauri_questionnaires_23-03-16T19-35-06.json') as f:\n",
    "#     lexicon = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bce74-d0fc-4a02-8205-51eafeffbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917dd4c6-deca-48f6-ad2a-691cb3587f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98588ca-b881-45db-80a6-7acbe93a3f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_df = pd.read_csv(input_dir_lexicons+'OsirisRankinFirstPassForDanLowMarch_3_ 2023_daniel_added_prototypes.csv', index_col = 0, encoding = 'latin1')\n",
    "\n",
    "print(len(lexicon_df.columns.tolist()))\n",
    "print(lexicon_df.columns.tolist()[:10])\n",
    "\n",
    "constructs_to_measure = ['self-injury',\n",
    " 'active_si',\n",
    " 'passive_si',\n",
    " 'bully',\n",
    " 'abuse_physical',\n",
    " 'abuse_sexual',\n",
    " 'relationships',\n",
    " 'grief_bereavement',\n",
    " 'loneliness_isolated',\n",
    " 'anxiety',\n",
    " 'depressed_mood',\n",
    " 'gender_sexual_identity',\n",
    " 'eating_disorder',\n",
    " 'substance_use']\n",
    "\n",
    "\n",
    "\n",
    "# values = ['']*len(constructs_to_measure)\n",
    "# ctl_tags = dict(zip(constructs_to_measure, values))\n",
    "ctl_tags_d = {'self-injury': 'self_harm',\n",
    " 'active_si': 'suicide',\n",
    " 'passive_si': 'suicide',\n",
    " 'bully': 'bully',\n",
    " 'abuse_physical': 'abuse_physical',\n",
    " 'abuse_sexual': 'abuse_sexual',\n",
    " 'relationships': 'relationship',\n",
    " 'grief_bereavement': 'bereavement',\n",
    " 'loneliness_isolated': 'isolated',\n",
    " 'anxiety': 'anxiety_stress',\n",
    " 'depressed_mood': 'depressed',\n",
    " 'gender_sexual_identity': 'gender_sexual_identity',\n",
    " 'eating_disorder': 'eating_body_image',\n",
    " 'substance_use': 'substance', \n",
    "  'alcohol_use': 'substance', \n",
    "             }\n",
    "\n",
    "ctl_tags = np.unique(list(ctl_tags_d.values())).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5548fd0-8cfe-4b6f-8113-b05011ce8b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_prototypes = {}\n",
    "\n",
    "# first create a list for each, so you can append \n",
    "for lexicon_construct, ctl_construct in ctl_tags_d.items():\n",
    "    lexicon_prototypes[ctl_construct] = []\n",
    "\n",
    "\n",
    "\n",
    "for lexicon_construct, ctl_construct in ctl_tags_d.items():\n",
    "    print(lexicon_construct, ctl_construct)\n",
    "    lexicon_df_construct_prototypes = lexicon_df[lexicon_df[lexicon_construct+'_remove'].isin(['prototype', 'seed_token'])][lexicon_construct].tolist()  \n",
    "    lexicon_prototypes[ctl_construct].extend(lexicon_df_construct_prototypes)\n",
    "    \n",
    "lexicon_prototypes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88a5a44-6a7e-4570-92ba-e4a22f26e920",
   "metadata": {},
   "source": [
    "# Remove tokens decided by osiris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57291f49-934e-4213-8c3a-a2312a3ab715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suicide_list_temp = ['I collected pills',\n",
    "#  'I gave my things away',\n",
    "#  'I wrote a suicide note',\n",
    "#  'attempt suicide',\n",
    "#  'auto exhaust',\n",
    "#  'commit suicide',\n",
    "#  'drive my car into a tree',\n",
    "#  'drown',\n",
    "#  'firearm',\n",
    "#  'giving away my possessions',\n",
    "#  'gun',\n",
    "#  'hang mysef',\n",
    "#  'immolation',\n",
    "#  'jump in front of a train',\n",
    "#  'jump into traffic',\n",
    "#  'jump of a bridge',\n",
    "#  'jump of a building',\n",
    "#  'jump of my balcony',\n",
    "#  'jump off a ledge',\n",
    "#  'kill myself',\n",
    "#  'make a will',\n",
    "#  'overdose',\n",
    "#  'pills',\n",
    "#  'poison',\n",
    "#  'rope',\n",
    "#  'rope around my neck',\n",
    "#  'set myself on fire',\n",
    "#  'suffocation',\n",
    "#  'suicide',\n",
    "#  'suicide attempt',\n",
    "#  'suicide note',\n",
    "#  'take all my pills',\n",
    "#  'thought about buying a gun',\n",
    "#  'thought about buying a rope',\n",
    "#  'thought about buying pills',\n",
    "#  'thought about hanging my self',\n",
    "#  'thought about jumping',\n",
    "#  'weapons',\n",
    "#  'write a will',\n",
    "# 'better if I was not alive',\n",
    "#  'go to sleep and never wake up',\n",
    "#  'hate my life',\n",
    "#  'my existence has no direction',\n",
    "#  'my existence has no meaning',\n",
    "#  \"my life doesn't seem worthwhile\",\n",
    "#  'my life has no clear aims',\n",
    "#  'my life has no clear goals',\n",
    "#  'my life has no sense of direction',\n",
    "#  'my life has no sense of meaning',\n",
    "#  'my life has no sense of purpose',\n",
    "#  'my life is going nowhere',\n",
    "#  'my personal existence has no purpose',\n",
    "#  'no one cares if I live or die',\n",
    "#  'nothing to look forward to',\n",
    "#  'there is no meaning to my life',\n",
    "#  'there is no purpose in what I am doing',\n",
    "#  \"there's nothing I want to achieve\",\n",
    "#  'want to die',\n",
    "#  'wish I had never been born',\n",
    "#  'wish I was never born',\n",
    "#  'wish I were dead']\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28033890-3318-4121-93aa-8f53c098a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon_remove = pd.read_csv('./../data/lexicons/suicidal_thoughts_and_behaviors/suicide_risk_lexicon_thesauri_questionnaires_23-03-16T19-35-06_osiris_v01.csv', index_col = 0,encoding='cp1252')\n",
    "# # suicide_list = lexicon_remove['active_si'].tolist()+lexicon_remove['passive_si'].tolist()\n",
    "# nans= ['nan']*(lexicon_remove.shape[1]+6)\n",
    "# lexicon_remove['suicide'] = suicide_list_temp+nans\n",
    "# lexicon_remove['suicide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef7d33-3e51-472e-8a88-136076738ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lexicon_remove_d = {}                            \n",
    "# for l in lexicon.keys():\n",
    "#     l=     ctl_tags_d_inv.get(l)\n",
    "#     if l=='suicide':\n",
    "#         lexicon_remove_d[l] = lexicon_remove_i\n",
    "#         continue\n",
    "\n",
    "#     lexicon_remove_i = lexicon_remove[[l,l+'_remove']].replace('seed_token', 0).replace('construct label', 1)\n",
    "#     lexicon_remove_i['self-injury_remove'] = lexicon_remove_i['self-injury_remove'].astype(float)\n",
    "    \n",
    "    \n",
    "#     lexicon_remove_i = lexicon_remove_i[lexicon_remove_i[l+'_remove']>=1][l].values\n",
    "#     lexicon_remove_i = [n for n in lexicon_remove_i if str(n)!= 'nan' ]\n",
    "#     print(lexicon_remove_i)    \n",
    "#     # to_remove_i = []\n",
    "#     lexicon_remove_d[l] = lexicon_remove_i\n",
    "    \n",
    "                             \n",
    "                             \n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13312126-eb86-49da-b52b-831ced9a9878",
   "metadata": {},
   "source": [
    "# define lexicons (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0376b2-5f9b-4b86-8640-d53369e0942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge active and passive\n",
    "# suicide_tokens = lexicon['active_si']+lexicon['passive_si']\n",
    "# suicide_tokens = [n for n in suicide_tokens if str(n)!='nan']\n",
    "# lexicon['suicide'] = suicide_tokens\n",
    "\n",
    "# # rename lexicon constructs\n",
    "# for k_old, k_new in ctl_tags_d.items():\n",
    "#     lexicon[k_new] = lexicon.pop(k_old)\n",
    "\n",
    "# # keep only ctl constructs\n",
    "# lexicon_constructs_not_in_ctl = set(lexicon.keys()) - set(ctl_tags_d.values())\n",
    "# lexicon_constructs_not_in_ctl\n",
    "# for construct in lexicon_constructs_not_in_ctl:\n",
    "#     del lexicon[construct]\n",
    "\n",
    "# # for construct-word to doc analyses, have a single construct \n",
    "# # lexicon_prototypes = dict(zip(lexicon.keys(), ['']*len(lexicon.keys())))\n",
    "\n",
    "\n",
    "# # use prototypes defined in suicide_risk_lexicon_thesauri_questionnaires_23-03-16T19-35-06_osiris_v01.csv \n",
    "\n",
    "# lexicon_prototypes = {'suicide': ['suicide', 'kill myself',\n",
    "#  'self_harm': 'I cut myself, self harm',\n",
    "#  'bully': \"bullied\",\n",
    "#  'abuse_physical': 'physical abuse, violence',\n",
    "#  'abuse_sexual': 'sexual abuse, rape',\n",
    "#  'relationship': 'relationship problems',\n",
    "#  'bereavement': \"grieving, mourning\",\n",
    "#  'isolated': 'lonely',\n",
    "#  'anxiety_stress': 'anxious',\n",
    "#  'depressed': 'depressed',\n",
    "#  'gender_sexual_identity': 'gender, queer, gay, sexual orientation',\n",
    "#  'eating_body_image': 'eating disorder, anorexia, bulimia',\n",
    "#  'substance': 'drugs, addiction, alcohol, drinking problem'}\n",
    "\n",
    "word_prototypes = {'suicide': 'suicide',\n",
    " 'self_harm': 'I cut myself',\n",
    " 'bully': \"bullied\",\n",
    " 'abuse_physical': 'physical abuse',\n",
    " 'abuse_sexual': 'sexual abuse and rape',\n",
    " 'relationship': 'relationship',\n",
    " 'bereavement': \"grieving and mourning\",\n",
    " 'isolated': 'lonely',\n",
    " 'anxiety_stress': 'anxious',\n",
    " 'depressed': 'depressed',\n",
    " 'gender_sexual_identity': 'gender and sexual orientation',\n",
    " 'eating_body_image': 'eating disorder',\n",
    " 'substance': 'drugs'}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f4b0a-6fb3-4124-8b8d-887cd8555d5a",
   "metadata": {},
   "source": [
    "# Encode lexicon\n",
    "\n",
    "you want to encode each token once, because can appear in multiple lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f9c6f9-2441-4d77-84f0-f3801d6b2dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1843f01-eba2-4240-9604-efcffb7c06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = './data/input/embeddings/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745a889-95bd-464a-bdc3-3df63935471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prior_encoded_embeddings = pd.read_csv(input_dir_catpro+'lexicons/suicidal_thoughts_and_behaviors/tokens_embeddings_22-12-02T17-43-57.csv', index_col = 0)\n",
    "# prior_encoded_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcae726-ccc1-47c9-8972-4dab2d66b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run\n",
    "# embedding_type = 'sentence' \n",
    "# docs = ['suicide', 'anxiety', 'sexual abuse and rape']\n",
    "# result = vectorize(docs, list_of_lists=False, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee5220-17a1-4644-8daf-1dfb089bdeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "\n",
    "\n",
    "run_this = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tokens_all = []\n",
    "for construct, tokens in lexicon_prototypes.items():\n",
    "    tokens_all.extend(tokens)\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "embedding_type = 'sentence'\n",
    "list_of_lists = False\n",
    "\n",
    "def \n",
    "    if run_or_load == 'run':\n",
    "        embeddings_lexicon_tokens = vectorize(tokens_all, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "        embeddings_lexicon_tokens_d = dict(zip(tokens_all, embeddings_lexicon_tokens))\n",
    "    \n",
    "    \n",
    "        with open(embeddings_dir+f'embeddings_prototypes_{model_name}.pickle', 'wb') as handle:\n",
    "            pickle.dump(embeddings_lexicon_tokens_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    else:        \n",
    "        with open(embeddings_dir+f'embeddings_prototypes_{model_name}.pickle', 'rb') as handle:\n",
    "            embeddings_lexicon_tokens_d = pickle.load(handle)\n",
    "        # with open(embeddings_dir+f'embeddings_{model_name}.pickle') as f:\n",
    "        #     embeddings_lexicon_tokens_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10b249-35a9-4bae-a7db-121eed01bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# run_this = True\n",
    "\n",
    "# embeddings_lexicon_tokens_d_protoypes = {}\n",
    "\n",
    "# if run_this:\n",
    "\n",
    "#     embeddings_lexicon_prototypes = vectorize(list(lexicon_prototypes.values()), list_of_lists=False, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "\n",
    "#     for k,v in zip(list(lexicon_prototypes.values()), embeddings_lexicon_prototypes):\n",
    "#         embeddings_lexicon_tokens_d_protoypes[k]=v\n",
    "#     # with open(embeddings_dir+f'embeddings_{model_name}.pickle', 'wb') as handle:\n",
    "#     #     pickle.dump(embeddings_lexicon_tokens_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa11a3-3532-4e6b-8655-98faa5838884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1f5fc3e-1f01-4ba3-8e52-3846caa7f59d",
   "metadata": {},
   "source": [
    "# Encode docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c030e-963e-41a6-93d4-8b48f1875e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl_tags13 = ['self_harm',\n",
    " 'suicide',\n",
    " 'bully',\n",
    " 'abuse_physical',\n",
    " 'abuse_sexual',\n",
    " 'relationship',\n",
    " 'bereavement',\n",
    " 'isolated',\n",
    " 'anxiety_stress',\n",
    " 'depressed',\n",
    " 'gender_sexual_identity',\n",
    " 'eating_body_image',\n",
    " 'substance']\n",
    "\n",
    "# identify test sets\n",
    "\n",
    "run_this = False\n",
    "\n",
    "datasets_dir = './../../../data/ctl/input/datasets/train10/'\n",
    "\n",
    "if run_this:\n",
    "    \n",
    "    test_set_ids = []\n",
    "    for dv in ctl_tags13:\n",
    "        df_i = create_binary_dataset(metadata_df, dv = dv, n_per_dv = 2500, random_state=123)\n",
    "        train_df,test_df = train_test_split(df_i, test_size=0.2,random_state=123)\n",
    "        train_df.to_csv(datasets_dir+f'train10_{dv}_train.csv')\n",
    "        test_df.to_csv(datasets_dir+f'train10_{dv}_test.csv')\n",
    "        test_set_ids.extend(test_df['conversation_id'].tolist())\n",
    "    \n",
    "    test_set_ids = np.unique(test_set_ids)\n",
    "else:\n",
    "    test_set_ids = []\n",
    "    for dv in ctl_tags13:\n",
    "        train_df = pd.read_csv(datasets_dir+f'train10_{dv}_train.csv', index_col = 0)\n",
    "        test_df = pd.read_csv(datasets_dir+f'train10_{dv}_test.csv', index_col = 0)\n",
    "        test_set_ids.extend(test_df['conversation_id'].tolist())\n",
    "    \n",
    "    test_set_ids = np.unique(test_set_ids)\n",
    "    print(test_set_ids.shape)    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8b0d6-0c93-4354-85b5-f80038982dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaf88d-9b92-4ec1-8638-345d24c6af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ed350-8c3d-4a0b-ade7-f340cf407806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtained docs tokenized into clauses:\n",
    "docs_clean_clauses_with_empty_strings = metadata_df[metadata_df['conversation_id'].isin(test_set_ids)]['docs_clean_clauses'].values\n",
    "\n",
    "docs_clean_clauses_convo_ids = metadata_df[metadata_df['conversation_id'].isin(test_set_ids)]['conversation_id'].values\n",
    "# IMPORTANT: eval so str becomes list of lists\n",
    "docs_clean_clauses_with_empty_strings = [eval(n) for n in docs_clean_clauses_with_empty_strings]\n",
    "\n",
    "# some clauses are empty strings '' . Could fix tokenizer\n",
    "docs_clean_clauses = []\n",
    "for doc in docs_clean_clauses_with_empty_strings:\n",
    "    clean_doc = [ x for x in doc if x != '']\n",
    "    docs_clean_clauses.append(clean_doc)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(len(docs_clean_clauses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba88d4c-b6ef-4931-aee1-cbfefa22e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# It's abuout 1m per 100 docs\n",
    "# 12 m for 1300 docs, each one tokenized\n",
    "# 100m 11000 docs, each one tokenized\n",
    "\n",
    "\n",
    "run_this = False\n",
    "\n",
    "\n",
    "\n",
    "if run_this:\n",
    "    pickle_name = 'clause_tokens_test_set'\n",
    "    model_name = 'all-MiniLM-L6-v2'\n",
    "    embedding_type = 'sentence'\n",
    "    list_of_lists = True\n",
    "    verbose = True\n",
    "    step = 1000\n",
    "\n",
    "    for i in range(0,len(docs_clean_clauses), step):\n",
    "        i_str = str(i).zfill(5)\n",
    "        print(f'vectorizing {i}-{i+step}')\n",
    "        docs_clean_clauses_i = docs_clean_clauses[i:i+step]\n",
    "        docs_clean_clauses_convo_ids_i = docs_clean_clauses_convo_ids[i:i+step]\n",
    "        embeddings_tokens_docs = vectorize(docs_clean_clauses_i, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs    \n",
    "        embeddings_tokens_docs_d = dict(zip(list(docs_clean_clauses_convo_ids_i), embeddings_tokens_docs))\n",
    "        with open(embeddings_dir+'train10_test/'+f'embeddings_docs_{model_name}_train10_train_concurrent_metadata_messages_{pickle_name}_{ts}_part-{i_str}.pickle', 'wb') as handle:\n",
    "            pickle.dump(embeddings_tokens_docs_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # save into smaller pickles. Then load and add to single pickle\n",
    "    embeddings_tokens_docs_d = {}\n",
    "    \n",
    "    keys_all = []\n",
    "    \n",
    "    for i in range(0,len(docs_clean_clauses), step):\n",
    "        i_str = str(i).zfill(5)\n",
    "        print(i_str)\n",
    "        docs_clean_clauses_convo_ids_i = docs_clean_clauses_convo_ids[i:i+step]\n",
    "        \n",
    "    \n",
    "        \n",
    "        with open(embeddings_dir+'train10_test/'+f'embeddings_docs_{model_name}_train10_train_concurrent_metadata_messages_{pickle_name}_{ts}_part-{i_str}.pickle', 'rb') as handle:\n",
    "            d_i = pickle.load(handle)\n",
    "            # the embeddings keys are range(0,1000). Change to convo IDs\n",
    "            # for i in range(len(d_i)):\n",
    "            #     new_key = docs_clean_clauses_convo_ids_i[i]\n",
    "            #     d_i[new_key] = d_i.pop(i)\n",
    "            embeddings_tokens_docs_d.update(d_i)\n",
    "            \n",
    "            # keys_all.append(list(embeddings_tokens_docs_d.keys()))\n",
    "            \n",
    "    \n",
    "    with open(embeddings_dir+'train10_test/'+f'embeddings_docs_{model_name}_train10_train_concurrent_metadata_messages_{pickle_name}_{ts}_part-all.pickle', 'wb') as handle:\n",
    "                pickle.dump(embeddings_tokens_docs_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    with open(embeddings_dir+'train10_test/'+'embeddings_docs_all-MiniLM-L6-v2_train10_train_concurrent_metadata_messages_clause_tokens_test_set_23-07-22T22-28-56_part-all.pickle', 'rb') as handle:\n",
    "    # with open(embeddings_dir+'train10_test/'+'embeddings_docs_all-MiniLM-L6-v2_train10_train_concurrent_metadata_messages_clause_tokens_test_set_23-07-21T16-33-40_part-all.pickle', 'rb') as handle:\n",
    "        embeddings_tokens_docs_d = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18b99df-a5de-4a86-a1f3-78f4f83faf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_tokens_docs_d.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7906d-5694-444a-ac48-03b82ae722b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test: passed\n",
    "# # take two random sentences. see if re-extracting matches mapping in d. \n",
    "\n",
    "# list(embeddings_tokens_docs_d.keys())[10005]\n",
    "# # 2 = 6934451.0, 10005 = 1856039.0\n",
    "# test_convo_ids = [6934451.0,  1856039.0]\n",
    "\n",
    "# test_docs = metadata_df[metadata_df['conversation_id'].isin(test_convo_ids)]['docs_clean_clauses'].values\n",
    "# test_docs = [eval(n) for n in test_docs]\n",
    "# test_docs_embeddings = vectorize(test_docs, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs    \n",
    "\n",
    "# for i, emb in enumerate(test_docs_embeddings):\n",
    "#     assert emb.tolist() == embeddings_tokens_docs_d.get(test_convo_ids[i]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357e6cb-f5ea-4e49-877e-59778c1c6df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# # 12 m for 1300 docs, each one tokenized\n",
    "\n",
    "\n",
    "# run_this = False\n",
    "\n",
    "# if run_this:\n",
    "#     model_name = 'all-MiniLM-L6-v2'\n",
    "#     embedding_type = 'sentence'\n",
    "#     list_of_lists = True\n",
    "#     verbose = True\n",
    "\n",
    "#     embeddings_tokens_docs = vectorize(docs_clean_clauses, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs    \n",
    "#     embeddings_tokens_docs_d = dict(zip(list(range(len(docs_clean_clauses))), embeddings_tokens_docs))\n",
    "#     with open(embeddings_dir+f'embeddings_docs_{model_name}_train10_train_concurrent_metadata_messages_{ts}.pickle', 'wb') as handle:\n",
    "#         pickle.dump(embeddings_tokens_docs_d, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# else:\n",
    "#     with open(embeddings_dir+'embeddings_docs_all-MiniLM-L6-v2_train10_train_concurrent_metadata_100perconstruct_with_messages.pickle', 'rb') as handle:\n",
    "#         embeddings_tokens_docs_d = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef5d12-0488-4e81-9814-555d01a683df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9300eac-0d6f-4497-a0a2-eb3c26b00300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c2fb1a-51bc-4588-9c23-a177c26b88b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructs = lexicon.keys()\n",
    "# construct_prototype_d = lexicon_prototypes\n",
    "# embeddings_construct_d = embeddings_lexicon_tokens_d\n",
    "# docs = docs_clean_clauses\n",
    "# embeddings_docs_d = embeddings_tokens_docs_d\n",
    "# method = 'word_clause'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e5a52-495d-4340-a749-66a02249f192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53409cde-547e-4a74-9ad1-39aff097f2d5",
   "metadata": {},
   "source": [
    "### TODO Encode tokes from words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2172a9-c221-4641-9cb0-c04c6c86087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "\n",
    "\n",
    "# feature_vectors_d = {}\n",
    "\n",
    "# for method in ['word_word']:\n",
    "    \n",
    "#     if method == 'word_word':\n",
    "#         docs = df['docs_clean_w_w'].values\n",
    "#     print('=========================')\n",
    "#     print(method)\n",
    "#     feature_vectors_all = cts.measure(\n",
    "#         constructs = lexicon.keys(),\n",
    "#         construct_prototype_d = lexicon_prototypes,\n",
    "#         embeddings_construct_d = embeddings_lexicon_tokens_d,\n",
    "#         docs = docs,\n",
    "#         embeddings_docs_d = ######TODO,\n",
    "#         method = method,\n",
    "#                                                    )\n",
    "#     feature_vectors_d[method]=feature_vectors_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73102e6-ba90-4552-8145-c68d7ee6c883",
   "metadata": {},
   "source": [
    "### todo: wlexicon for weightedLexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27fce10-ddae-4bd8-9f2d-c3d79dac3485",
   "metadata": {},
   "source": [
    "### word_ methods for prototype and lexicon_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d679cf0-9440-4efc-8f79-5ceafec59836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9814f269-902a-4e3e-ae9d-58774c29f91a",
   "metadata": {},
   "source": [
    "### Check encoding is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce02706-b11d-4c43-8fcf-09af727f9d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # construct \n",
    "# lexicon_prototypes\n",
    "\n",
    "# construct embeddings\n",
    "# embeddings_lexicon_tokens_d\n",
    "\n",
    "# # docs (test set sentences)\n",
    "# docs_clean_clauses\n",
    "\n",
    "# # doc embeddings (test set sentence embeddings)\n",
    "# len(embeddings_tokens_docs_d.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2b651-713f-4dc7-b9dc-517f799b3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one of the construct tokens and their embeddings\n",
    "\n",
    "tokens = lexicon_prototypes.get('self_harm') \n",
    "print(tokens)\n",
    "token_embeddings = np.array([embeddings_lexicon_tokens_d.get(token) for token in tokens]) # obtain one of the construct tokens\n",
    "print(token_embeddings.shape)\n",
    "token_embeddings2 = vectorize(tokens)\n",
    "\n",
    "assert token_embeddings == token_embeddings2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51b12c-adb6-495a-91c6-204bbc8fe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one of the doc tokens and their embeddings\n",
    "df_example = metadata_df[metadata_df['docs_clean_clauses'].str.contains(\"Feeling very suicidal and about to take pills just need someone|i feel alone and\")]\n",
    "# display(df_example)\n",
    "docs_i = [eval(n) for n in df_example['docs_clean_clauses'].values]\n",
    "docs_i_clean = []\n",
    "for doc in docs_i:\n",
    "    clean_doc = [ x for x in doc if x != '']\n",
    "    docs_i_clean.append(clean_doc)\n",
    "    \n",
    "docs_i_embeddings = vectorize(docs_i_clean, list_of_lists=True)\n",
    "docs_i_embeddings_d = dict(zip(df_example['conversation_id'].values, docs_i_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ac46b-4188-4221-a90d-ce6847ae60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_protoypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d51893-58e5-4a29-a254-0e95dd8fa82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(cts)\n",
    "\n",
    "method = 'lexicon_clause'\n",
    "feature_vectors_i, cosine_scores_docs_i = cts.measure(\n",
    "            construct_tokens_d = construct_tokens_d,\n",
    "    \t\tconstruct_embeddings_d = construct_embeddings_d,\n",
    "    \t\tdocs = docs_i,\n",
    "    \t\tdocs_embeddings_d = docs_i_embeddings_d,\n",
    "    \t\tmethod = method, #todo: change to token, tokens, weighted_tokens\n",
    "    \t\tsummary_stat = ['max']\n",
    "        )\n",
    "\n",
    "feature_vectors_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c25ec-03c9-415b-a6be-4e57addd8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test: passed, \n",
    "construct = 'bully'\n",
    "feature_vectors_all_copy = feature_vectors_all.copy()\n",
    "feature_vectors_i_d = dict(zip(feature_vectors_i['doc_id'].values, feature_vectors_i[construct+'_max'].values))\n",
    "# feature_vectors_all_copy[construct+'_max2'] = feature_vectors_all_copy['doc_id'].map(feature_vectors_i_d)\n",
    "# feature_vectors_all_copy[~feature_vectors_all_copy[construct+'_max2'].isna()][[construct+'_max', construct+'_max2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac2764-22fb-4796-bd7c-ed43b3982382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ctl_tags13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1b7e9e-2fb4-4e50-a829-85da7eceee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23269f8-dd88-484f-99ec-b9dedbb8e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_all[feature_vectors_all['doc_id']==doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8846e-3397-44ee-96a4-062e46c36fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for doc_id, score in feature_vectors_i_d.items():\n",
    "#     print('============='*3)\n",
    "#     print('doc_id', doc_id)\n",
    "#     metadata_df_i = metadata_df[metadata_df['conversation_id']==doc_id]\n",
    "#     for tag in ctl_tags13:\n",
    "#         if metadata_df_i[tag].values[0]==1:\n",
    "#             score = feature_vectors_i[feature_vectors_i['doc_id']==doc_id][tag+'_max'].round(2).values[0]\n",
    "            \n",
    "#             print(tag, 'true', 1, '\\tcts predicted', score)\n",
    "#     display(np.array(eval(metadata_df_i['docs_clean_clauses'].values[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e7f1b-cc03-4890-a2a7-89880b1f463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean_clauses_i = metadata_df['conversation_id']==1909812.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d523dcfa-02aa-4dc7-81be-ee2283ecd610",
   "metadata": {},
   "source": [
    "# Construct text similarity (once construct and doc are encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e421ad1-9c87-43a8-badc-90561cafb2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1f9bb6-48d6-4297-a804-59f8d7d9885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['conversation_id']==3137630.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a3eb2-827e-4000-b458-6a79e0956f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any non strings in tokens?\n",
    "[type(n) for n in tokens_all if type(n)!=str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0fbb5-ab2e-47cb-8b6f-9f9db2ca2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any empty tokens?\n",
    "[n[:2] for n in np.array(list(embeddings_lexicon_tokens_d.values()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c4dfc-db50-44c1-ba09-cb8f240ef60c",
   "metadata": {},
   "source": [
    "### compute with word prototypes (see below for proper code, then turn that into a function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c57e3-6a6c-41fa-a06b-b5af50afa52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(cts)\n",
    "# toy\n",
    "\n",
    "# doc_i = eval(metadata_df[metadata_df['message'].str.contains('skinny and beautiful')]['docs_clean_clauses'].values[0])[:5]\n",
    "docs_clean_clauses_i = [[\"I'm scared that I might develop an eating disorder like anorexia\", 'Yea for as long as I could remember I felt fat', 'my family said that I never looked pretty because I weighed so much', 'And now in college I walk around', 'see girls who are extremely skinny and beautiful']]\n",
    "docs_clean_clauses_i_embeddings = vectorize(docs_clean_clauses_i, list_of_lists=True)\n",
    "\n",
    "embeddings_tokens_docs_d_i = {12345678:docs_clean_clauses_i_embeddings[0]}\n",
    "\n",
    "print(docs_clean_clauses_i)\n",
    "\n",
    "feature_vectors_all,cosine_scores_docs_all = cts.measure(\n",
    "        construct_tokens_d = construct_tokens_d,\n",
    "        construct_embeddings_d = construct_embeddings_d,\n",
    "        docs = docs_clean_clauses_i,\n",
    "        docs_embeddings_d = embeddings_tokens_docs_d_i,\n",
    "        method = method, #todo: change to token, tokens, weighted_tokens\n",
    "        summary_stat = ['max'],\n",
    "    return_cosine_similarity=True\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "feature_vectors_all\n",
    "print(cosine_scores_docs_all)\n",
    "doc_id = 12345678\n",
    "construct = 'eating_body_image'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c236a531-ebaf-4fd0-942c-f2bf00d9cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2f452-28f7-4461-92d2-0a8dbd65419a",
   "metadata": {},
   "source": [
    "### compute with lexicon prototypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ca7a3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4617b6c-449e-4794-a79f-5239411de2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_all = []\n",
    "for construct, tokens in lexicon_prototypes.items():\n",
    "    tokens_all.extend(tokens)\n",
    "embeddings_lexicon_tokens = vectorize(tokens_all, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "embeddings_lexicon_tokens_d = dict(zip(tokens_all, embeddings_lexicon_tokens))\n",
    "construct_tokens_d = lexicon_prototypes.copy()\n",
    "construct_embeddings_d = embeddings_lexicon_tokens_d.copy()\n",
    "\n",
    "from importlib import reload\n",
    "reload(cts)\n",
    "# toy\n",
    "\n",
    "# doc_i = eval(metadata_df[metadata_df['message'].str.contains('skinny and beautiful')]['docs_clean_clauses'].values[0])[:5]\n",
    "docs_clean_clauses_i = [[\"I'm scared that I might develop an eating disorder like anorexia\", 'Yea for as long as I could remember I felt fat', 'my family said that I never looked pretty because I weighed so much', 'And now in college I walk around', 'see girls who are extremely skinny and beautiful']]\n",
    "docs_clean_clauses_i_embeddings = vectorize(docs_clean_clauses_i, list_of_lists=True)\n",
    "\n",
    "embeddings_tokens_docs_d_i = {12345678:docs_clean_clauses_i_embeddings[0]}\n",
    "\n",
    "print(docs_clean_clauses_i)\n",
    "\n",
    "feature_vectors_all,cosine_scores_docs_all = cts.measure(\n",
    "        construct_tokens_d = construct_tokens_d,\n",
    "        construct_embeddings_d = construct_embeddings_d,\n",
    "        docs = docs_clean_clauses_i,\n",
    "        docs_embeddings_d = embeddings_tokens_docs_d_i,\n",
    "        method = 'lexicon_clause', #todo: change to token, tokens, weighted_tokens\n",
    "        summary_stat = ['max'],\n",
    "    return_cosine_similarity=True\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "feature_vectors_all\n",
    "print(cosine_scores_docs_all)\n",
    "doc_id = 12345678\n",
    "construct = 'eating_body_image'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8378b-30a9-4f3d-9815-db11de16fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(n, '\\n') for n in np.round(cosine_scores_docs_all.get(str(doc_id)+'_'+construct),2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62fa423-73c4-4cc7-9ffe-18f6d4750a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680507ca-4e7d-4e6b-abe7-2451737d6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "[print(n, '\\n') for n in docs_clean_clauses_i[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441f8a5-56a9-4ab3-b19d-627a4825fc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd7d8c7-6056-4228-b0ec-da137f43dfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens_all)/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c2b08e-0fad-432c-bbfd-563cd69fb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_vectors_all.to_csv(f'./data/input/datasets/cts_prototypes-clauses_prototypes_clause_{ts}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5c145-139b-442a-a11c-5ad483170009",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prototypes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cd0bc-5e62-474e-86a7-63be4e189930",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_all[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88846b0a-9b0c-47f6-9d0c-44065e0259f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_all[0].to_csv(f'./data/input/datasets/cts_testsets_{method}_clause_{ts}.csv')\n",
    "with open(f'./data/input/datasets/cts_testsets_{method}_clause_{ts}.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_vectors_d, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6b0d5-af04-4dfe-8326-9464400effe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# if construct==1 word, then 10k takes about 1 min\n",
    "# if construct==about 10 words on average, then 10k takes about 17 min\n",
    "from importlib import reload\n",
    "reload(cts)\n",
    "\n",
    "method = 'word_clause' #['word_clause', 'lexicon_clause']\n",
    "run_this = False\n",
    "\n",
    "\n",
    "model_name = 'all-MiniLM-L6-v2'\n",
    "embedding_type = 'sentence'\n",
    "list_of_lists = False\n",
    "\n",
    "if run_this:\n",
    "\n",
    "    \n",
    "\n",
    "    print('=========================')\n",
    "    print(method)\n",
    "    if method == 'lexicon_clause':\n",
    "        # encode construct\n",
    "        tokens_all = []\n",
    "        for construct, tokens in lexicon_prototypes.items():\n",
    "            tokens_all.extend(tokens)\n",
    "        embeddings_lexicon_tokens = vectorize(tokens_all, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "        embeddings_lexicon_tokens_d = dict(zip(tokens_all, embeddings_lexicon_tokens))\n",
    "        \n",
    "        # define dicttionaries\n",
    "        construct_tokens_d = lexicon_prototypes.copy()\n",
    "        construct_embeddings_d = embeddings_lexicon_tokens_d.copy()\n",
    "\n",
    "    elif method == 'word_clause':\n",
    "        # encode construct\n",
    "        tokens_all = word_prototypes.values()\n",
    "        embeddings_word_tokens = vectorize(tokens_all, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "        embeddings_word_tokens_d = dict(zip(tokens_all, embeddings_word_tokens))\n",
    "        \n",
    "        # define dicttionaries\n",
    "        construct_tokens_d = word_prototypes.copy()\n",
    "        construct_embeddings_d = embeddings_word_tokens_d.copy()\n",
    "        \n",
    "    feature_vectors_all = cts.measure(\n",
    "        construct_tokens_d = construct_tokens_d,\n",
    "        construct_embeddings_d = construct_embeddings_d,\n",
    "        docs = docs_clean_clauses,\n",
    "        docs_embeddings_d = embeddings_tokens_docs_d,\n",
    "        method = method, #todo: change to token, tokens, weighted_tokens\n",
    "        summary_stat = ['max']\n",
    "    )\n",
    "    feature_vectors_all.to_csv(f'./data/input/datasets/cts_testsets_{method}_clause_{ts}.csv')\n",
    "    with open(f'./data/input/datasets/cts_testsets_{method}_clause_{ts}.pkl', 'wb') as f:\n",
    "        pickle.dump(feature_vectors_d, f)\n",
    "\n",
    "\n",
    "else:\n",
    "    if method == 'word_clause':\n",
    "        feature_vectors_all = pd.read_csv(f'./data/input/datasets/cts_testsets_word_clause_clause_23-07-22T22-28-56.csv')\n",
    "    elif method == 'lexicon_clause':\n",
    "        feature_vectors_all = pd.read_csv(f'./data/input/datasets/cts_testsets_lexicon_clause_23-07-22T22-28-56.csv')\n",
    "    \n",
    "    # # with open(f'./data/input/datasets/cts_testsets_prototypes_clause_23-07-22T16-39-15.pkl', 'rb') as f:\n",
    "    # with open(f'./data/input/datasets/cts_testsets_{method}_clause_23-07-22T16-39-15.pkl', 'rb') as f:\n",
    "    #     feature_vectors_d = pickle.load(f)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da7821f-1eb1-4f63-8ef2-6366721c71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors_all = feature_vectors_all.sort_values('doc_id')\n",
    "feature_vectors_all2 == feature_vectors_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a826aa1-90b7-4203-aeb8-b629b3737c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "idx = 3137630.0\n",
    "\n",
    "print(metadata_df[metadata_df['conversation_id']==idx]['message'].values)\n",
    "\n",
    "feature_vectors_all[feature_vectors_all['doc_id']==idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d12bc09-7e66-49c6-ae41-4db8f4ef6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "\n",
    "\n",
    "# feature_vectors_d = {}\n",
    "\n",
    "# for method in ['lexicon_clause']:#['word_clause', 'lexicon_clause']:\n",
    "#     print('=========================')\n",
    "#     print(method)\n",
    "#     feature_vectors_all = cts.measure(\n",
    "#         constructs = lexicon.keys(),\n",
    "#         construct_prototype_d = lexicon_prototypes,\n",
    "#         embeddings_construct_d = embeddings_lexicon_tokens_d,\n",
    "#         docs = docs_clean_clauses,\n",
    "#         embeddings_docs_d = embeddings_tokens_docs_d,\n",
    "#         method = method,\n",
    "#                                                    )\n",
    "#     feature_vectors_d[method]=feature_vectors_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a625db-a015-4cef-a9f7-de964ff98ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38ebd5-e690-4659-b42a-9a9a243349ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import other_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1807659-a4dd-4342-a469-610068133431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79848ae2-efdf-41af-8c5d-be4814aaf6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ddf201-8b93-4944-a3ce-42ad14954d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# calculate the fpr and tpr for all thresholds of the classification\n",
    "# probs = model.predict_proba(X_test)\n",
    "# preds = probs[:,1]\n",
    "\n",
    "# Softmax. not really making sense.\n",
    "# https://discuss.pytorch.org/t/logits-vs-log-softmax/95979\n",
    "\n",
    "\n",
    "figsize = (4,4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f4b96-2ee4-4d2d-a5d5-1c3c2d9e80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_vectors_all = feature_vectors_d.get(method) # DF feature vector for each doc, the max score with each construct\n",
    "# feature_vectors_all_d = dict(zip(feature_vectors_all['doc_id'], feature_vectors_all[construct+'_max']))\n",
    "# print(len(feature_vectors_all_d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e8068-633f-47ba-b556-3eb00c0d1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct = 'isolated'\n",
    "# test_df = pd.read_csv(datasets_dir+f'train10_{construct}_test.csv', index_col = 0)\n",
    "# test_df[construct+'_max'] = test_df['conversation_id'].map(feature_vectors_all_d)\n",
    "# test_df[['message', construct, construct+'_max']].values[5:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ff950-22cc-4d11-b81b-f38509354b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexicon_prototypes.get('suicide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862579fc-5ea9-4eb7-8d0d-33986c0e3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_toy = ['Feeling very suicidal and about to take pills just need someone to talk to','take all my pills', 'suicide', 'I suppose my husband finally figured out I was trying to leave and threatened to kill himself.', 'kill myself', 'kill']\n",
    "# embeddings_toy = vectorize(docs_toy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1471ae-6df0-4ed2-a2c8-a080811853e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine_similarity(embeddings_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b66c53-caf3-446d-a7a7-04d5319dbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct = 'relationship'\n",
    "# # lexicon_prototypes\n",
    "# # embeddings_lexicon_tokens_d\n",
    "# construct_i_embeddings = []\n",
    "# for token in lexicon_prototypes.get(construct):\n",
    "#     construct_i_embeddings.append(embeddings_lexicon_tokens_d.get(token))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806f717-d20b-4ae9-821b-10b47d638651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs_i = metadata_df[metadata_df['conversation_id'].isin([7263937.0, 3870339.0])]['docs_clean_clauses'].values\n",
    "# docs_i = [eval(n) for n in docs_i]\n",
    "# docs_i_embeddings = vectorize(docs_i, list_of_lists=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a13165-c9fe-4d81-9a8e-2d6b9267a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct_i_embeddings = np.stack(construct_i_embeddings, axis=0).astype(float)\n",
    "# for docs_i_embeddings_i in docs_i_embeddings:\n",
    "#     docs_i_embeddings_i = np.stack(docs_i_embeddings_i, axis=0).astype(float)\n",
    "#     cosine_scores_docs_i = cosine_similarity(construct_i_embeddings, docs_i_embeddings_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7becec-df82-454f-906d-68fc4417503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(construct_i_embeddings.shape)\n",
    "# print(docs_i_embeddings_i.shape)\n",
    "# cosine_scores_docs_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e94cf1-6222-4ca6-ae2c-e785cf623988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(cosine_scores_docs_i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd2e7bf-05a7-4189-939b-b21bc39c8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(cosine_scores_docs_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb911fd-d1b5-434c-b2a4-74430ecd68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_vectors_all_d = dict(zip(feature_vectors_all['doc_id'], feature_vectors_all[construct+'_max']))\n",
    "\n",
    "# docs_toy = ['Feeling very suicidal and about to take pills just need someone to talk to','take all my pills', 'suicide', 'I suppose my husband finally figured out I was trying to leave and threatened to kill himself.', 'kill myself', 'kill']\n",
    "# embeddings_toy = vectorize(docs_toy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2da0727-1026-4972-a1c7-943b3950b30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl_tags13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2a4169-f993-4c18-817e-7ee006ea19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_names = ['Precision','Recall', 'Specificity', 'F1','Avg. Precision', 'ROC AUC']\n",
    "# results_05 = pd.DataFrame(results_all_05, index = metric_names).T.round(3)\n",
    "# print(results_05.mean())\n",
    "# results_05.loc['Mean', results_05.columns] = results_05.mean().round(3)\n",
    "# display(results_05)\n",
    "\n",
    "# results_045 = pd.DataFrame(results_all_045, index =metric_names).T.round(3)\n",
    "# results_045.loc['Mean', results_045.columns] = results_045.mean().round(3)\n",
    "# display(results_045)\n",
    "\n",
    "# results_04 = pd.DataFrame(results_all_04, index =metric_names).T.round(3)\n",
    "# results_04.loc['Mean', results_04.columns] = results_04.mean().round(3)\n",
    "# display(results_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df3267-ca1d-4976-aff4-31ea4b951495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_to_df(y_true, y_pred,y_proba=None, model_name='Model X', add_stats = True, round_to_decimal = 3):\n",
    "\t# todo: add metric options\n",
    "\tresults_d = {}\n",
    "\tprecision = metrics.precision_score(y_true,y_pred,average = 'binary')\n",
    "\trecall = metrics.recall_score(y_true,y_pred,average = 'binary')\n",
    "\tspecificity = metrics.recall_score(y_true, y_pred, pos_label=0,average = 'binary')\n",
    "\tf1 = metrics.f1_score(y_true,y_pred,average = 'binary')\n",
    "\tavg_pr = metrics.average_precision_score(y_true, y_proba)\n",
    "\troc_auc = metrics.roc_auc_score(y_true,y_proba)\n",
    "\tresults_d[model_name] = [precision, recall,specificity, f1, avg_pr, roc_auc]\n",
    "\tmetric_names = ['Precision','Recall', 'Specificity', 'F1','Avg. Precision', 'ROC AUC']\n",
    "\tresults_df = pd.DataFrame(results_d, index = metric_names).T.round(round_to_decimal)\n",
    "\tresults_df.mean()\n",
    "\tif add_stats:\n",
    "\t\tresults_df.loc['Mean', results_df.columns] = results_df.mean().round(round_to_decimal)\n",
    "        results_df.loc['Min', results_df.columns] = results_df.min().round(round_to_decimal)\n",
    "        results_df.loc['Max', results_df.columns] = results_df.max().round(round_to_decimal)\n",
    "        \n",
    "\treturn results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5205a2-0340-43cd-957e-a0792276db2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f05b5-ba2b-4200-9127-4b154795374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from importlib import reload\n",
    "reload(other_metrics)\n",
    "\n",
    "import time \n",
    "\n",
    "dcor_all = []\n",
    "    \n",
    "r_all = []\n",
    "results_all_05 = {}\n",
    "results_all_045 = {}\n",
    "results_all_04 = {}\n",
    "\n",
    "from sklearn import metrics\n",
    "plot_roc_pr = False\n",
    "plot_density = False # hanging here for some reason\n",
    "results_d = {}\n",
    "\n",
    "# for method in ['lexicon_clause']:# ['word_clause', lexicon_clause']\n",
    "print(method)\n",
    "# feature_vectors_all = feature_vectors_d.get(method) # DF feature vector for each doc, the max score with each construct\n",
    "\n",
    "# tags = metadata_df[constructs] # ground truth\n",
    "\n",
    "\n",
    "# max_cols = [n+'_max' for n in constructs]\n",
    "# feature_vectors_all_max = feature_vectors_all[max_cols]\n",
    "# assert [n+'_max' for n in constructs] == max_cols  #make sure they're in the right order\n",
    "# feature_vectors_all_max.columns = constructs        \n",
    "# dcor\n",
    "# dcor_i = dcor.distance_correlation(tags,feature_vectors_all_max) \n",
    "# dcor_all.append(dcor_i)\n",
    "# print('dcor', dcor_i)\n",
    "\n",
    "r_method_i = []\n",
    "results_d = {}\n",
    "for construct in ctl_tags13:# ctl_tags13:#['self_harm']: #:\n",
    "    print('==='*80)\n",
    "    print(construct)\n",
    "    # training_samples = 300 # up to 4000\n",
    "    # train_df = pd.read_csv(datasets_dir+f'train10_{construct}_train.csv', index_col = 0).sample(n=training_samples)\n",
    "    # y_train = train_df[construct].values\n",
    "    test_df = pd.read_csv(datasets_dir+f'train10_{construct}_test.csv', index_col = 0)\n",
    "    feature_vectors_all_d = dict(zip(feature_vectors_all['doc_id'], feature_vectors_all[construct+'_max']))\n",
    "    test_df[construct+'_max'] = test_df['conversation_id'].map(feature_vectors_all_d)\n",
    "    # test_df[['conversation_id', construct, construct+'_max']]\n",
    "    y_true = test_df[construct].values\n",
    "    y_pred = test_df[construct+'_max'].values\n",
    "\n",
    "    # y_true_1 = tags[tags[construct]==1] # obtain N samples that where construct == 1, others should == 0 due to preprocessing\n",
    "    # y_true_0 = tags[tags[construct]==0].sample(n=y_true_1.shape[0]) # match to y_true_1 N in length\n",
    "    # y_true_1_indexes = y_true_1.index.tolist()\n",
    "    # y_true_0_indexes = y_true_0.index.tolist()\n",
    "    # y_true = pd.concat([y_true_1,y_true_0],axis=0)[construct].values # combine y=0 and y=1 and same size\n",
    "    # y_pred = feature_vectors_all_max[construct][y_true_1_indexes+y_true_0_indexes].values\n",
    "\n",
    "    \n",
    "\n",
    "    # dcor_i = dcor.distance_correlation(y_true,y_pred) #0.45\n",
    "    # print(construct, f'dcor={np.round(dcor_i,2)}', np.round(r,2), np.round(p, 4))\n",
    "\n",
    "    # df_i = pd.DataFrame(feature_vectors_all_max[construct][y_true_1_indexes+y_true_0_indexes])\n",
    "   \n",
    "    \n",
    "\n",
    "    #here y_pred is max cosine similarity \n",
    "    roc_auc = roc_auc_score(y_true,y_pred)\n",
    "    avg_pr = average_precision_score(y_true, y_pred)\n",
    "    print('roc auc', np.round(roc_auc,3))\n",
    "    print('avg_pr', np.round(avg_pr,3))\n",
    "    if plot_roc_pr:\n",
    "        metricsother_metrics.plot_roc_auc_curve(y_true, y_pred)\n",
    "        other_metrics.plot_precision_recall_curve(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_df['05-threshold'] = test_df[construct+'_max']>=0.5\n",
    "    test_df['045-threshold'] = test_df[construct+'_max']>=0.45\n",
    "    test_df['04-threshold'] = test_df[construct+'_max']>=0.4\n",
    "\n",
    "    # correlation \n",
    "    r, p = pointbiserialr(y_true,y_pred)\n",
    "    if p < 0.001:\n",
    "        p = '***'\n",
    "    elif 0.01 > p >= 0.001:\n",
    "        p = '**'\n",
    "    elif 0.05 > p >= 0.01:\n",
    "        p = '*'\n",
    "    elif p > 0.05:\n",
    "        p = ''\n",
    "        \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "    # class_report = classification_report(y_true,y_pred)\n",
    "    # print(construct)\n",
    "    # print(class_report)\n",
    "\n",
    "    \n",
    "    \n",
    "            \n",
    "    # Cohens D\n",
    "    # ===========================\n",
    "    y_pred_0 = test_df[test_df[construct]==0][construct+'_max'].values\n",
    "    y_pred_1 = test_df[test_df[construct]==1][construct+'_max'].values\n",
    "    # cohens_d = (np.mean(y_pred_1) - np.mean(y_pred_0)) / (np.sqrt((np.std(y_pred_1) ** 2 + np.std(y_pred_0) ** 2) / 2))\n",
    "    cohens_d = other_metrics.cohend(y_pred_1,y_pred_0)\n",
    "    # rocauc = roc_auc_score(y_true,y_pred)\n",
    "    # rocauc = str(np.round(roc_auc_score,2))\n",
    "    title_i = f\"{construct}: rho={np.round(r,2)}{p} Cohen's {np.round(cohens_d,2)}\"\n",
    "    print(title_i)\n",
    "    \n",
    "    if plot_density: \n",
    "        \n",
    "        # display(df_i)\n",
    "        sns.kdeplot(data=test_df,x = construct+'_max', hue=construct)\n",
    "        plt.title(title_i)\n",
    "        plt.show()\n",
    "    # r_method_i.append(r)\n",
    "\n",
    "\n",
    "        \n",
    "    # r_all_method_i_stats.append(\n",
    "        \n",
    "    \n",
    "    for threshold in ['05-threshold', '04-threshold', '045-threshold']:\n",
    "        y_pred = test_df[threshold].values\n",
    "        y_true = test_df[construct].values\n",
    "        f1 = f1_score(y_true,y_pred,average = 'binary')\n",
    "        precision = precision_score(y_true,y_pred,average = 'binary')\n",
    "        recall = recall_score(y_true,y_pred,average = 'binary')\n",
    "        specificity = metrics.recall_score(y_true, y_pred, pos_label=0,average = 'binary')\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "        if '05-' in threshold:\n",
    "            results_all_05[construct] = [precision, recall,specificity, f1, avg_pr, roc_auc, r, cohens_d]\n",
    "        elif '04-' in threshold:\n",
    "            results_all_04[construct] = [precision, recall, specificity, f1, avg_pr,roc_auc, r, cohens_d]\n",
    "        elif '045-' in threshold:\n",
    "            results_all_045[construct] = [precision, recall, specificity, f1, avg_pr ,roc_auc, r, cohens_d]\n",
    "\n",
    "# r_all.append(r_method_i)\n",
    "# stats = np.round([np.mean(r_all), np.std(r_all),np.min(r_all),np.max(r_all)],2)\n",
    "# print(f'stats: {stats[0]} ± {stats[1]} ({stats[2]}-{stats[3]})')\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20229a6-10ec-4c46-b3f0-328388e9d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric_names = ['Precision','Recall', 'Specificity','F1',  'ROC AUC']\n",
    "# results = pd.DataFrame(results_d, index = metric_names).T.round(3)\n",
    "# results_mean = results.mean().round(3)\n",
    "# results_min = results.min().round(3)\n",
    "# results_max = results.max().round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27000923-b567-4109-abfb-23651c1e58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_05.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fcee5a-f1c3-454b-b76d-7b934fda8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(other_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a42af-db93-4ca9-a248-2535ce54fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from other_metrics import su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2563a1-2559-43f4-a52f-d3ed70c8f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './data/output/construct_text_similarity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f882cb09-5fa2-45fa-b841-a38afff630cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['Precision','Recall', 'Specificity', 'F1','Avg. Precision', 'ROC AUC', 'point-biserial', \"Cohen's D\"]\n",
    "\n",
    "\n",
    "results_05 = pd.DataFrame(results_all_05, index = metric_names).T.round(2)\n",
    "# results_05.loc['Mean', results_05.columns] = results_05.mean().round(2)\n",
    "results_05.loc['Mean [min-max]', results_05.columns] = other_metrics.summary_metrics_df(results_05).values[0]\n",
    "results_05.to_csv(output_dir+f'results_train10_{method}_threshold-050.csv')\n",
    "display(results_05)\n",
    "\n",
    "results_045 = pd.DataFrame(results_all_045, index =metric_names).T.round(2)\n",
    "results_045.loc['Mean [min-max]', results_045.columns] = other_metrics.summary_metrics_df(results_045).values[0]\n",
    "results_045.to_csv(output_dir+f'results_train10_{method}_threshold-045.csv')\n",
    "display(results_045)\n",
    "\n",
    "results_04 = pd.DataFrame(results_all_04, index =metric_names).T.round(2)\n",
    "results_04.loc['Mean [min-max]', results_04.columns] = other_metrics.summary_metrics_df(results_04).values[0]\n",
    "results_04.to_csv(output_dir+f'results_train10_{method}_threshold-040.csv')\n",
    "display(results_04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278740b2-97ac-4c1d-ac4f-bbd64e7bc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_04.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91f1452-09a1-4990-9259-2c56a771ced2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04b522-9ed0-439c-994b-9e5005fb7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e1fccd4-b433-4630-9d70-b2a206d9cb49",
   "metadata": {},
   "source": [
    "# correlation with presence of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4fcea-3d43-4b7f-bad0-3b93255b0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctl_tags13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c624e5-a716-468d-9faa-bdb7b6afc47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from importlib import reload\n",
    "reload(other_metrics)\n",
    "\n",
    "words_pointbiserial = {}\n",
    "\n",
    "import time \n",
    "\n",
    "dcor_all = []\n",
    "    \n",
    "r_all = []\n",
    "results_all_05 = {}\n",
    "results_all_045 = {}\n",
    "results_all_04 = {}\n",
    "\n",
    "from sklearn import metrics\n",
    "plot_roc_pr = False\n",
    "plot_density = False # hanging here for some reason\n",
    "results_d = {}\n",
    "\n",
    "# for method in ['lexicon_clause']:# ['word_clause', lexicon_clause']\n",
    "print(method)\n",
    "# feature_vectors_all = feature_vectors_d.get(method) # DF feature vector for each doc, the max score with each construct\n",
    "\n",
    "# tags = metadata_df[constructs] # ground truth\n",
    "\n",
    "\n",
    "# max_cols = [n+'_max' for n in constructs]\n",
    "# feature_vectors_all_max = feature_vectors_all[max_cols]\n",
    "# assert [n+'_max' for n in constructs] == max_cols  #make sure they're in the right order\n",
    "# feature_vectors_all_max.columns = constructs        \n",
    "# dcor\n",
    "# dcor_i = dcor.distance_correlation(tags,feature_vectors_all_max) \n",
    "# dcor_all.append(dcor_i)\n",
    "# print('dcor', dcor_i)\n",
    "\n",
    "r_method_i = []\n",
    "results_d = {}\n",
    "words = ['eating', 'body', 'fat','ugly', 'binge', 'skinny', 'gained', 'anorexia', 'image', 'struggle', 'purging', 'starving','bulimia']\n",
    "\n",
    "for word_i in words:\n",
    "    \n",
    "    for construct in ['eating_body_image']:#ctl_tags13:# ctl_tags13:#['self_harm']: #:\n",
    "        print('==='*80)\n",
    "        print(construct)\n",
    "        # training_samples = 300 # up to 4000\n",
    "        # train_df = pd.read_csv(datasets_dir+f'train10_{construct}_train.csv', index_col = 0).sample(n=training_samples)\n",
    "        # y_train = train_df[construct].values\n",
    "        test_df = pd.read_csv(datasets_dir+f'train10_{construct}_test.csv', index_col = 0)\n",
    "        feature_vectors_all_d = dict(zip(feature_vectors_all['doc_id'], feature_vectors_all[construct+'_max']))\n",
    "        test_df[construct+'_max'] = test_df['conversation_id'].map(feature_vectors_all_d)\n",
    "        # test_df[['conversation_id', construct, construct+'_max']]\n",
    "        y_true = test_df[construct].values\n",
    "        y_pred = test_df[construct+'_max'].values\n",
    "    \n",
    "        # y_true_1 = tags[tags[construct]==1] # obtain N samples that where construct == 1, others should == 0 due to preprocessing\n",
    "        # y_true_0 = tags[tags[construct]==0].sample(n=y_true_1.shape[0]) # match to y_true_1 N in length\n",
    "        # y_true_1_indexes = y_true_1.index.tolist()\n",
    "        # y_true_0_indexes = y_true_0.index.tolist()\n",
    "        # y_true = pd.concat([y_true_1,y_true_0],axis=0)[construct].values # combine y=0 and y=1 and same size\n",
    "        # y_pred = feature_vectors_all_max[construct][y_true_1_indexes+y_true_0_indexes].values\n",
    "    \n",
    "        \n",
    "    \n",
    "        # dcor_i = dcor.distance_correlation(y_true,y_pred) #0.45\n",
    "        # print(construct, f'dcor={np.round(dcor_i,2)}', np.round(r,2), np.round(p, 4))\n",
    "    \n",
    "        # df_i = pd.DataFrame(feature_vectors_all_max[construct][y_true_1_indexes+y_true_0_indexes])\n",
    "       \n",
    "        \n",
    "    \n",
    "        #here y_pred is max cosine similarity \n",
    "        roc_auc = roc_auc_score(y_true,y_pred)\n",
    "        avg_pr = average_precision_score(y_true, y_pred)\n",
    "        print('roc auc', np.round(roc_auc,3))\n",
    "        print('avg_pr', np.round(avg_pr,3))\n",
    "        if plot_roc_pr:\n",
    "            metricsother_metrics.plot_roc_auc_curve(y_true, y_pred)\n",
    "            other_metrics.plot_precision_recall_curve(y_true, y_pred)\n",
    "        \n",
    "    \n",
    "    \n",
    "        test_df['presence_of_word_i'] = test_df['message'].str.contains(word_i).values\n",
    "        from scipy.stats import pointbiserialr\n",
    "        r,p = pointbiserialr(test_df['presence_of_word_i'], y_pred)\n",
    "        print(word_i, np.round(r,2)    )\n",
    "        words_pointbiserial[word_i] = np.round(r,2)\n",
    "    \n",
    "pd.DataFrame(words_pointbiserial, index= ['cts']).T.to_csv(output_dir+'point_biserial_top_words.csv')\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        # test_df['05-threshold'] = test_df[construct+'_max']>=0.5\n",
    "        # test_df['045-threshold'] = test_df[construct+'_max']>=0.45\n",
    "        # test_df['04-threshold'] = test_df[construct+'_max']>=0.4\n",
    "    \n",
    "        # # correlation \n",
    "        # r, p = pointbiserialr(y_true,y_pred)\n",
    "        # if p < 0.001:\n",
    "        #     p = '***'\n",
    "        # elif 0.01 > p >= 0.001:\n",
    "        #     p = '**'\n",
    "        # elif 0.05 > p >= 0.01:\n",
    "        #     p = '*'\n",
    "        # elif p > 0.05:\n",
    "        #     p = ''\n",
    "            \n",
    "        \n",
    "    \n",
    "            \n",
    "        \n",
    "    \n",
    "        # # class_report = classification_report(y_true,y_pred)\n",
    "        # # print(construct)\n",
    "        # # print(class_report)\n",
    "    \n",
    "        \n",
    "        \n",
    "                \n",
    "        # # Cohens D\n",
    "        # # ===========================\n",
    "        # y_pred_0 = test_df[test_df[construct]==0][construct+'_max'].values\n",
    "        # y_pred_1 = test_df[test_df[construct]==1][construct+'_max'].values\n",
    "        # # cohens_d = (np.mean(y_pred_1) - np.mean(y_pred_0)) / (np.sqrt((np.std(y_pred_1) ** 2 + np.std(y_pred_0) ** 2) / 2))\n",
    "        # cohens_d = other_metrics.cohend(y_pred_1,y_pred_0)\n",
    "        # # rocauc = roc_auc_score(y_true,y_pred)\n",
    "        # # rocauc = str(np.round(roc_auc_score,2))\n",
    "        # title_i = f\"{construct}: rho={np.round(r,2)}{p} Cohen's {np.round(cohens_d,2)}\"\n",
    "        # print(title_i)\n",
    "        \n",
    "        # if plot_density: \n",
    "            \n",
    "        #     # display(df_i)\n",
    "        #     sns.kdeplot(data=test_df,x = construct+'_max', hue=construct)\n",
    "        #     plt.title(title_i)\n",
    "        #     plt.show()\n",
    "        # # r_method_i.append(r)\n",
    "    \n",
    "    \n",
    "            \n",
    "        # r_all_method_i_stats.append(\n",
    "            \n",
    "        \n",
    "        # for threshold in ['05-threshold', '04-threshold', '045-threshold']:\n",
    "        #     y_pred = test_df[threshold].values\n",
    "        #     y_true = test_df[construct].values\n",
    "        #     f1 = f1_score(y_true,y_pred,average = 'binary')\n",
    "        #     precision = precision_score(y_true,y_pred,average = 'binary')\n",
    "        #     recall = recall_score(y_true,y_pred,average = 'binary')\n",
    "        #     specificity = metrics.recall_score(y_true, y_pred, pos_label=0,average = 'binary')\n",
    "            \n",
    "    \n",
    "                \n",
    "    \n",
    "        #     if '05-' in threshold:\n",
    "        #         results_all_05[construct] = [precision, recall,specificity, f1, avg_pr, roc_auc, r, cohens_d]\n",
    "        #     elif '04-' in threshold:\n",
    "        #         results_all_04[construct] = [precision, recall, specificity, f1, avg_pr,roc_auc, r, cohens_d]\n",
    "        #     elif '045-' in threshold:\n",
    "        #         results_all_045[construct] = [precision, recall, specificity, f1, avg_pr ,roc_auc, r, cohens_d]\n",
    "    \n",
    "    # r_all.append(r_method_i)\n",
    "    # stats = np.round([np.mean(r_all), np.std(r_all),np.min(r_all),np.max(r_all)],2)\n",
    "    # print(f'stats: {stats[0]} ± {stats[1]} ({stats[2]}-{stats[3]})')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56e101-5904-48ac-ada9-a568c7dbda1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07025716-81fd-4e28-8dea-6de5ded26da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4ca49f-a99c-49ef-bd2e-e14846366f29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68250147-63fc-44f5-9a57-3113ac0e4b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ceaf383-a5a5-4a79-9f92-c361351cde48",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583eae78-bc45-43c3-9566-26bc18405b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2221c-2ad8-4b40-918c-1525bb85c4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96573eef-067b-42ff-8427-c96f84dc8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=df_i,x = construct, hue='Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df146d7c-3db4-4617-bf9a-4b18adac7c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e84cc2-f90f-4a70-b9d6-987540feed24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86aff82-3f8a-4410-84ab-98a385e519b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_cols = [n+'_max' for n in constructs]\n",
    "\n",
    "# for c in constructs:\n",
    "#     print(c)\n",
    "#     feature_vectors_all_max_docs = feature_vectors_all[['doc']+max_cols].sort_values([construct+'_max'])[::-1]['doc'].values[:5]\n",
    "#     [print('. '.join(eval(n)), '\\n') for n in feature_vectors_all_max_docs]\n",
    "#     # print(feature_vectors_all_max_docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df3bbb-2cfb-4ed3-bca2-122f8b9b6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in feature_vectors_all.index:\n",
    "#     truth = dict(zip(constructs, df[constructs].iloc[idx,:].values))\n",
    "#     print(truth)\n",
    "    \n",
    "#     features = feature_vectors_all.iloc[idx,:].values\n",
    "#     print('. '.join(eval(features[0])))\n",
    "#     print(features[1:])\n",
    "          \n",
    "#     max_cols = [n+'_max' for n in constructs]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13339b5d-adc8-4e2a-97f0-8b8b3a478505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dcor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e0c37-d295-460a-9d07-e964b553858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33334890-bc7a-42c8-ac96-a95a6e1202b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# tags = df[constructs]\n",
    "\n",
    "# max_cols = [n+'_max' for n in constructs]\n",
    "# word_clause_max = feature_vectors_all[max_cols]\n",
    "# assert [n+'_max' for n in constructs] == max_cols \n",
    "# word_clause_max.columns = constructs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12d9c9-edb3-40e0-b251-b719da3cb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_clause_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e3404f-92b3-453b-991f-92bb0b14c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcor_lexicon_clause_max = dcor.distance_correlation(tags,lexicon_clause_max) #0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f488dc-ebd0-4f0e-b018-f67bc6bfd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcor_lexicon_clause_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69186f85-8dc9-4163-b0ab-946cea2135ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f20933-2625-44da-a199-025e55b2d7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_clause_max.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9b40b-6e95-4645-926b-7226aff61fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tags.columns.tolist() == word_clause_max.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886df18a-76e5-46f1-aea5-30ecb8c8b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "for construct in constructs:\n",
    "    y_true_1 = tags[tags[construct]==1]\n",
    "    y_true_0 = tags[tags[construct]==0].sample(n=y_true_1.shape[0])\n",
    "    y_true_1_indexes = y_true_1.index.tolist()\n",
    "    y_true_0_indexes = y_true_0.index.tolist()\n",
    "    y_true = pd.concat([y_true_1,y_true_0],axis=0)[construct].values\n",
    "    # y_true = y_true.sample(n=y_true.shape[0])\n",
    "    y_pred = word_clause_max[construct][y_true_1_indexes+y_true_0_indexes].values\n",
    "    r, p = spearmanr(y_true,y_pred)\n",
    "    print(construct, np.round(r,2), np.round(p, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae7b7e6-14b0-45d5-85d2-b23dbd8e4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9e6c0-cebf-40b8-a62e-7b82f3a84888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a919501c-635b-4890-885b-29ae72551eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96166ee-98e5-4ff3-afe5-cebc0702417d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f591a1-722f-4260-a1a2-888f10873cdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d5f86-06b5-4819-b7d6-ef626e726963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2aa211-1935-439a-b7d6-ebdb50a2170d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa671b5-06c0-4815-9ff5-f5e759bc29dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b3c4f-fa0f-4421-82b7-72be3052b50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplotword_clause_max[construct][y_true_1_indexes].values\n",
    "word_clause_max[construct][y_true_0_indexes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cccef-725e-48d8-97f2-b42963ae42cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dd41e-2356-465c-b98b-69c988e4bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in constructs:\n",
    "    y_true = tags[construct].values\n",
    "    y_pred = word_clause_max[construct]\n",
    "    r, p = spearmanr(y_true,y_pred)\n",
    "    print(construct, np.round(r,2), np.round(p, 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6780a8-2f3c-456b-85cf-c84fa4776644",
   "metadata": {},
   "outputs": [],
   "source": [
    "for construct in constructs:\n",
    "    y_true = tags[construct].values\n",
    "    y_pred = word_clause_max[construct]\n",
    "    r, p = spearmanr(y_true,y_pred)\n",
    "    print(construct, np.round(r,2), np.round(p, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be34fc24-2311-4fd4-8359-4f827c47bb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b312c9e-e7f6-4c92-b3f8-514e55b5e09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32365d99-8319-43ae-bd49-a4d4ad937aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # embeddings_tokens_docs ={}\n",
    "\n",
    "# feature_vectors_all = []\n",
    "\n",
    "# for i, doc in enumerate(docs_clean_clauses[:10]):\n",
    "#     if i%100==0:\n",
    "#         print(i)\n",
    "#     embeddings_tokens_doc_i = vectorize(doc, list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7ecac7-ec10-4a63-aac1-b121e1f87588",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# embeddings_tokens_docs ={}\n",
    "\n",
    "feature_vectors_all = []\n",
    "\n",
    "\n",
    "embeddings_tokens_doc_i = vectorize(docs_clean_clauses[:10], list_of_lists=list_of_lists, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab438dbf-57f7-4f83-9583-b2691610a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding_construct_prototype.shape) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7fda09-1396-45f3-b593-260daf35167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_vectors_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d883104-44dc-4e8f-9b90-da33ffac61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#     for i in docs_embeddings:\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# # def df_similarity_token_category(embeddings_tokens_doc, constructs_d, df, docs_clean, summary_stats = None):\n",
    "# #     '''\n",
    "# #     embeddings_tokens_doc\n",
    "# #     '''\n",
    "# # for each doc, it creates a value (e.g., mean across tokens --either words or clauses) for each construct    \n",
    "\n",
    "# feature_vectors_mean = []\n",
    "# feature_vectors_median = []\n",
    "# feature_vectors_max = []\n",
    "\n",
    "# constructs = list(constructs_d.keys())\n",
    "\n",
    "# for i, doc in enumerate(docs_clean):\n",
    "#     embeddings_tokens_doc_i = embeddings_tokens_doc[i]\n",
    "#     df_scores_category_all = pd.DataFrame(docs_clean[i], columns = ['token'])\n",
    "#     for category in constructs:\n",
    "#         embedding_category = constructs_d.get(category)\n",
    "#         embedding_category = np.array(embedding_category, dtype=float)\n",
    "#         embeddings_tokens_doc_i = np.array(embeddings_tokens_doc_i, dtype=float)\n",
    "#         if embeddings_tokens_doc_i.shape[0] == 0: #happens when there is an empty str\n",
    "#             embeddings_tokens_doc_i = [np.zeros(embedding_category.shape[0])]\n",
    "#         cosine_scores = cosine_similarity(embedding_category, embeddings_tokens_doc_i)\n",
    "#         # each token is a row, and each col is a construct being measured for that token.             \n",
    "#         df_scores_category_all[category] = np.array(cosine_scores, dtype = float)[0]#pd.DataFrame(cosine_scores, columns = ['category'])\n",
    "\n",
    "\n",
    "#         # df_scores_category = pd.DataFrame([docs_clean[i], np.array(cosine_scores[0])]).T\n",
    "#         # df_scores_category.columns = ['token', category]\n",
    "#         # df_scores_category = df_scores_category.sort_values(by='token')\n",
    "#         # # df_scores_category_all= df_scores_category_all.merge(df_scores_category, on='token', how = 'outer')\n",
    "#         # df_scores_category_all.append(df_scores_category)\n",
    "#     # df_scores_category_all = pd.concat(df_scores_category_all, axis=1)\n",
    "#     df_scores_category_all = df_scores_category_all[constructs].astype(float)\n",
    "\n",
    "#     # display(df_scores_category_all)\n",
    "#     feature_vectors_mean.append(df_scores_category_all.mean())\n",
    "#     feature_vectors_median.append(df_scores_category_all.median())\n",
    "#     feature_vectors_max.append(df_scores_category_all.max())\n",
    "\n",
    "# feature_vectors_mean = pd.concat(feature_vectors_mean,axis=1).T\n",
    "# feature_vectors_mean.columns = [n+'_mean' for n in feature_vectors_mean.columns]\n",
    "\n",
    "# feature_vectors_median = pd.concat(feature_vectors_median,axis=1).T\n",
    "# feature_vectors_median.columns = [n+'_median' for n in feature_vectors_median.columns]\n",
    "\n",
    "# feature_vectors_max = pd.concat(feature_vectors_max,axis=1).T\n",
    "# feature_vectors_max.columns = [n+'_max' for n in feature_vectors_max.columns]\n",
    "\n",
    "# feature_vectors = pd.concat([feature_vectors_mean, feature_vectors_median, feature_vectors_max],axis=1)\n",
    "# df[feature_vectors.columns.tolist()] = feature_vectors.values\n",
    "# # feature_cols = list(set(feature_vectors.columns)-set(['subreddit','author','date','docs','docs_clean']))\n",
    "# # feature_cols.sort()\n",
    "# # feature_vectors= feature_vectors[['subreddit','author','date','docs','docs_clean']+feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77561dc2-df5d-4e01-913f-0b509d331190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_dir+f'train10_train_concurrent_metadata_100perconstruct_with_messages_preprocessed_23-03-20T17-50-34.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0b522-c235-4ca4-bbbf-96f6c41471af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_embeddings = {}\n",
    "print('encoding...')\n",
    "embeddings_tokens_doc = vectorize(docs_final, list_of_lists=True, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "# encode tokens of each doc\n",
    "np.save(npy_filepath, embeddings_tokens_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0d197-df96-4645-a46c-2e8fb89f1c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103d7a99-af7e-4aa8-9991-57a35e56c6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2cfabe-94d8-4118-bab2-7b303255ce75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c77a4c-cedc-4083-8fef-5b968fce8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05685017-be64-45d8-81bf-833c56efeff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd3ca9-bb3e-45e4-b3ce-81750a69912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "constructs_suicide_risk_lexicon_weighted_centroid = pd.read_csv('./../data/lexicons/suicidal_thoughts_and_behaviors/weighted_centroids_22-12-04T01-06-02.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7447f-cded-44e2-ac92-6a5049f9b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_this = True\n",
    "\n",
    "lexicons_dir = './../data/lexicons/'\n",
    "embeddings_path = lexicons_dir+'embeddings_tokens_all-MiniLM-L6-v2_22-12-02T17-32-05.json'\n",
    "tokens_path = lexicons_dir+'suicidal_thoughts_and_behaviors/concurrent_validity_tokens_cosine_similarity_22-12-02T17-43-57.csv'\n",
    "\n",
    "\n",
    "\n",
    "if run_this:\n",
    "    for approach_embedding_name in approach_embedding_names:\n",
    "        if 'glove' in approach_embedding_name:\n",
    "            model_name = 'glove'\n",
    "\n",
    "        elif 'minilm' in approach_embedding_name:\n",
    "            model_name = 'all-MiniLM-L6-v2'\n",
    "        elif 'psychbert' in approach_embedding_name:\n",
    "            model_name = 'mnaylor/psychbert-cased'\n",
    "        \n",
    "        embedding_type = embedding_name_type.get(model_name)\n",
    "        # if model_name in [\n",
    "        #     # 'mnaylor/psychbert-cased',# cannot run on Mac M1, will run on colab: vectorize(docs_clean_joined, package = 'transformers', model_name = 'mnaylor/psychbert-cased', embedding_type = 'document')\n",
    "        #     # 'all-MiniLM-L6-v2',\n",
    "        #     # 'glove',\n",
    "        #                 ]:\n",
    "        #     continue # skip      \n",
    "        print('approach_embedding_name: ', approach_embedding_name, 'model_name:', model_name, 'embedding_type: ', embedding_type)\n",
    "\n",
    "        len_docs = len(docs_clean)\n",
    "        # print(len_constructs , docs_per_construct )\n",
    "        \n",
    "        if '_w' in approach_embedding_name:\n",
    "            docs_final = df['docs_clean_w_w'].values\n",
    "            # df = pd.read_csv(output_dir+'feature_vectors_16constructs_7subreddits_156docs_w_w_minilm_22-10-09T02-19-07.csv', index_col = 0)\n",
    "            # df = df.iloc[:, :5]\n",
    "        elif '_c' in approach_embedding_name:\n",
    "            docs_final = df['docs_clean_w_c'].values\n",
    "            # df = pd.read_csv(output_dir+'feature_vectors_16constructs_7subreddits_156docs_w_c_minilm_22-10-09T02-19-07.csv', index_col = 0)\n",
    "            # df = df.iloc[:, :5]\n",
    "        df['docs_final']=docs_final\n",
    "\n",
    "\n",
    "        type_of_document_tokenization = '_'.join(approach_embedding_name.split('_')[-2:]) #w, c\n",
    "\n",
    "        \n",
    "        npy_filepath = output_dir+f'army_starrs_{len(constructs)}constructs_{len_docs}docs_{type_of_document_tokenization}_embeddings.npy'\n",
    "        try:\n",
    "            embeddings_tokens_doc = np.load(npy_filepath,\n",
    "                                            allow_pickle=True)\n",
    "            print('loaded from prior run')\n",
    "\n",
    "        except:\n",
    "            print('did not find: ',npy_filepath)\n",
    "            print('encoding...')\n",
    "            embeddings_tokens_doc = vectorize(docs_final, list_of_lists=True, embedding_type = embedding_type, model_name = model_name) # 10 s for list of tokens for 5200 docs\n",
    "            # encode tokens of each doc\n",
    "            np.save(npy_filepath, embeddings_tokens_doc)\n",
    "\n",
    "        filename = model_name.split('/')[-1]\n",
    "\n",
    "        if approach_embedding_name.startswith('wl_'):\n",
    "            # centroid weighted by cosine sim to construct label             \n",
    "\n",
    "            constructs_d = {}\n",
    "            # Load embedings for construct\n",
    "            with open(embeddings_path, 'r') as json_file:\n",
    "                lexicons_embeddings = json.load(json_file)\n",
    "\n",
    "            lexicons_tokens = pd.read_csv(tokens_path, index_col = 0)\n",
    "            for construct in lexicons_tokens['construct'].unique():\n",
    "                weighted_centroid = constructs_suicide_risk_lexicon_weighted_centroid[construct].values\n",
    "                constructs_d[construct]=weighted_centroid\n",
    "                # lexicons_tokens_i = lexicons_tokens[lexicons_tokens['construct']==construct]\n",
    "                # tokens_i = lexicons_tokens_i['token'].values\n",
    "                # scores_i = lexicons_tokens_i['score'].values\n",
    "                # embeddings_i = np.array([lexicons_embeddings.get(token) for token in tokens_i])\n",
    "                # weighted_centroid = np.average(embeddings_i, axis=0, weights=scores_i)\n",
    "                \n",
    "                \n",
    "            print('loaded dict of construct embeddings')\n",
    "\n",
    "        else:\n",
    "            try: \n",
    "#               # TODO:\n",
    "                with open(output_dir+f'constructs{len(constructs)}_{approach_embedding_name}.pkl', 'rb') as f:\n",
    "                    constructs_d = pickle.load(f)\n",
    "                print('loaded dict of construct embeddings')\n",
    "            except:\n",
    "                print('encoding construct embeddings...')    \n",
    "                # encode constructs     \n",
    "                constructs_d = {}\n",
    "                embeddings_constructs = vectorize(constructs, embedding_type = embedding_type, model_name = model_name)\n",
    "                for category, embedding in zip(constructs, embeddings_constructs):\n",
    "                    constructs_d[category] = embedding\n",
    "                with open(output_dir+f'constructs{len(constructs)}_{approach_embedding_name}.pkl', 'wb') as f:\n",
    "                    pickle.dump(constructs_d, f)\n",
    "\n",
    "        # compute similarity (extract features)    \n",
    "        # embeddings_tokens_doc = np.load(output_dir+f'army_starrs_5_{model_name.split('/')[-1]}_embeddings.npy')\n",
    "        # constructs_d['hallucinating'] = constructs_d['hallucinating_hallucination']\n",
    "        # del  constructs_d['hallucinating_hallucination']\n",
    "\n",
    "        feature_vectors = df_similarity_token_category(embeddings_tokens_doc, constructs_d, df, docs_final, summary_stats = None)\n",
    "        feature_vectors.to_csv(output_dir+f'feature_vectors_{len(constructs)}constructs_{len_docs}docs_{approach_embedding_name}_{ts}.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
