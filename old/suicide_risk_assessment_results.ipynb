{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074a219-4bab-455b-b1ea-19f3c7867945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef2ef8-de02-447b-9167-b2a86062fd50",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89352df-84c7-45cb-9d67-68e3c52dd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Authors: Daniel M. Low\n",
    "License: See license in github repository\n",
    "'''\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "ts = datetime.datetime.utcnow().strftime('%y-%m-%dT%H-%M-%S')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "# pd.options.display.width = 0\n",
    "\n",
    "\n",
    "# os.chdir(os.path.dirname(__file__)) # Set working directory to current file\n",
    "\n",
    "on_colab = False\n",
    "\n",
    "if on_colab:\n",
    "  from google.colab import drive\n",
    "  project_name = 'project_name'\n",
    "  drive.mount('/content/drive')\n",
    "  results_dir = f'/content/drive/MyDrive/datum/{project_name}/data/input/'\n",
    "  output_dir = f'/content/drive/MyDrive/datum/{project_name}/data/output/'\n",
    "else:\n",
    "  input_dir = './../data/'\n",
    "  output_dir = './../data/output/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693940d7-a13b-44cc-b90d-3809d17d4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "balance = True # balance training set by downsampling\n",
    "task = 'regression'\n",
    "target = 'immiment_risk'\n",
    "normalize_lexicon = True\n",
    "\n",
    "\n",
    "\n",
    "if task == 'classification':\n",
    "\tdv = 'suicide_ladder_classification'\n",
    "\tif target == 'suicidal_desire':\n",
    "\t\tbalance_values = ['nonsuicidal','suicidal_desire']\n",
    "\telif target == 'imminent_risk':\n",
    "\t\tbalance_values = ['suicidal_desire','imminent_risk']\n",
    "\tsmallest_value = 'imminent_risk'\n",
    "\tn = 1893\n",
    "\n",
    "elif task == 'regression':\n",
    "\n",
    "\t# config\n",
    "\tdv = 'suicide_ladder_a'\n",
    "\tbalance_values = [1,2,3]\n",
    "\tsmallest_value = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec373cd-cdd9-4e47-b4cd-95501255b992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_feature_importance_df(trained_model, model_name, feature_names, xgboost_method = 'weight', model_name_in_pipeline = 'estimator', lgbm_method='split'):\n",
    "\t'''\n",
    "\tFunction to generate feature importance table for methods that use .coef_ from sklearn\n",
    "\tas well as xgboost models.\n",
    "\tboth using sklearn pipelines that go into GridsearchCV, where we need to \n",
    "\tfirst access the best_estimator to access, for example, the coefficients.\n",
    "\t\n",
    "\ttrained_model: sklearn type model object fit to data\n",
    "\tmodel_name: str among the ones that appear below\n",
    "\txgboost_method: str, there are a few options: https://xgboost.readthedocs.io/en/stable/python/python_api.html#xgboost.Booster.get_score     \n",
    "\t'''\n",
    "\t\n",
    "\t#  Feature importance using coefficients for linear models and gini \n",
    "\tif model_name in ['SGDRegressor', 'Ridge', 'Lasso', 'LogisticRegression', 'LinearSVC']:\n",
    "\t\ttry:\n",
    "\t\t\tcoefs = list(trained_model.named_steps['model'].coef_)\n",
    "\t\texcept:\n",
    "\t\t\tcoefs = list(trained_model.best_estimator_.named_steps[model_name_in_pipeline].coef_)                     # Obtain coefficients from GridSearch\n",
    "\t\ttry:\n",
    "\t\t\tcoefs= pd.DataFrame(coefs,index = ['Coef.'], columns = feature_names).T # make DF\n",
    "\t\texcept:\n",
    "\t\t\tcoefs= pd.DataFrame(coefs,index=feature_names, columns = ['Coef.']) # make DF\n",
    "\t\tcoefs['Abs. Coef.'] = coefs['Coef.'].abs()  # add column with absolute values to sort by, both positive and negative values are important. \n",
    "\t\tcoefs= coefs.sort_values('Abs. Coef.', ascending=False).reset_index() # sort by abs value and reset index to add a feature name column\n",
    "\t\tcoefs= coefs.drop(['Abs. Coef.'], axis=1)   # drop abs value, it's job is done\n",
    "\t\tcoefs.index +=1                             # Importance for publication, start index with 1 , as in 1st, 2nd, 3rd\n",
    "\t\tcoefs= coefs.reset_index()                  # turn index into column\n",
    "\t\tcoefs.columns= ['Importance', 'Feature', 'Coef.'] # Clean column names\n",
    "\t\tfeature_importance = coefs.copy()\n",
    "\t\treturn feature_importance\n",
    "\t\t\n",
    "\telif model_name in ['LGBMRegressor', 'LGBMClassifier']:    \n",
    "\t\ttry:\n",
    "\t\t\timportance_split = trained_model.named_steps[model_name_in_pipeline].booster_.feature_importance(importance_type='split')\n",
    "\t\t\timportance_gain = trained_model.named_steps[model_name_in_pipeline].booster_.feature_importance(importance_type='gain')\n",
    "\t\t\t# feature_names = trained_model.named_steps[model_name_in_pipeline].booster_.feature_name()\n",
    "\t\texcept:\n",
    "\t\t\timportance_split = trained_model.best_estimator_.named_steps[model_name_in_pipeline].booster_.feature_importance(importance_type='split')\n",
    "\t\t\timportance_gain = trained_model.best_estimator_.named_steps[model_name_in_pipeline].booster_.feature_importance(importance_type='gain')\n",
    "\t\t\t# feature_names = trained_model.best_estimator_.named_steps[model_name_in_pipeline].booster_.feature_name()\n",
    "\t\t\n",
    "\t\tfeature_importance = pd.DataFrame({'feature': feature_names, 'split': importance_split, 'gain': importance_gain})\n",
    "\t\t\n",
    "\t\t# Sort by gain\n",
    "\t\tfeature_importance = feature_importance.sort_values('gain', ascending=False)\n",
    "\t\treturn feature_importance\n",
    "\n",
    "\t\t\n",
    "\n",
    "\telif model_name in ['XGBRegressor', 'XGBClassifier']:\n",
    "\t\t# WARNING it will not return values for features that weren't used: if feature 3 wasn't used there will not be a f3 in the results        \n",
    "\t\ttry:\n",
    "\t\t\tfeature_importance = trained_model.named_steps[model_name_in_pipeline].get_booster().get_score(importance_type=xgboost_method )\n",
    "\t\texcept:\n",
    "\t\t\tfeature_importance = trained_model.best_estimator_.named_steps[model_name_in_pipeline].get_booster().get_score(importance_type=xgboost_method )\n",
    "\t\tfeature_importance_keys = list(feature_importance .keys())\n",
    "\t\tfeature_importance_values = list(feature_importance .values())    \n",
    "\t\tfeature_importance = pd.DataFrame(feature_importance_values,index=feature_importance_keys) # make DF\n",
    "\t\tfeature_importance = feature_importance .sort_values(0, ascending=False)\n",
    "\t\tfeature_importance = feature_importance.reset_index()\n",
    "\t\n",
    "\t\tfeature_importance.index +=1\n",
    "\t\tfeature_importance = feature_importance.reset_index()\n",
    "\t\tfeature_importance\n",
    "\t\t\n",
    "\t\t\n",
    "\t\tfeature_importance.columns = ['Importance', 'Feature', xgboost_method.capitalize()]\n",
    "\t\t\n",
    "\t\tfeature_name_mapping = {}\n",
    "\t\tfor i, feature_name_i in enumerate(feature_names):\n",
    "\t\t\tfeature_name_mapping[f'f{i}'] = feature_name_i\n",
    "\t\t\n",
    "\t\t# Or manually edit here: \n",
    "\t\t# feature_name_mapping = {'f0': 'Unnamed: 0', 'f1': 'Adult Mortality', 'f2': 'infant deaths', 'f3': 'percentage expenditure', 'f4': 'Hepatitis B', 'f5': 'Measles ', 'f6': ' BMI ', 'f7': 'under-five deaths ', 'f8': 'Polio', 'f9': 'Diphtheria ', 'f10': ' HIV/AIDS', 'f11': ' thinness  1-19 years', 'f12': ' thinness 5-9 years', 'f13': 'Developing'}\n",
    "\t\t\n",
    "\t\tfeature_importance['Feature'] = feature_importance['Feature'].map(feature_name_mapping )\n",
    "\t# Todo: add feature_importances_ for sklearn tree based models\n",
    "\t# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#feature-importance-based-on-mean-decrease-in-impurity\n",
    "\t\n",
    "\t\n",
    "\t\treturn feature_importance\n",
    "\telse:\n",
    "\t\twarnings.warn(f'model not specificied for feature importance: {model_name}')\n",
    "\t\treturn None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13503de4-7a56-4321-a726-bbdfee674ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "liwc_nonsemantic = ['WC','WPS',\n",
    " 'BigWords',\n",
    " 'Dic',\n",
    " 'Linguistic',\n",
    " 'function',\n",
    " 'pronoun',\n",
    " 'ppron',\n",
    " 'i',\n",
    " 'we',\n",
    " 'you',\n",
    " 'shehe',\n",
    " 'they',\n",
    " 'ipron',\n",
    " 'det',\n",
    " 'article',\n",
    " 'number',\n",
    " 'prep',\n",
    " 'auxverb',\n",
    " 'adverb',\n",
    " 'conj',\n",
    " 'negate',\n",
    " 'verb',\n",
    " 'adj',\n",
    " 'quantity',\n",
    " 'AllPunc',\n",
    " 'Period',\n",
    " 'Comma',\n",
    " 'QMark',\n",
    " 'Exclam',\n",
    " 'Apostro',\n",
    " 'OtherP'\n",
    "]\n",
    "\n",
    "liwc_semantic = ['Analytic',\n",
    " 'Clout',\n",
    " 'Authentic',\n",
    " 'Tone', \n",
    " 'Drives',\n",
    " 'affiliation',\n",
    " 'achieve',\n",
    " 'power',\n",
    " 'Cognition',\n",
    " 'allnone',\n",
    " 'cogproc',\n",
    " 'insight',\n",
    " 'cause',\n",
    " 'discrep',\n",
    " 'tentat',\n",
    " 'certitude',\n",
    " 'differ',\n",
    " 'memory',\n",
    " 'Affect',\n",
    " 'tone_pos',\n",
    " 'tone_neg',\n",
    " 'emotion',\n",
    " 'emo_pos',\n",
    " 'emo_neg',\n",
    " 'emo_anx',\n",
    " 'emo_anger',\n",
    " 'emo_sad',\n",
    " 'swear',\n",
    " 'Social',\n",
    " 'socbehav',\n",
    " 'prosocial',\n",
    " 'polite',\n",
    " 'conflict',\n",
    " 'moral',\n",
    " 'comm',\n",
    " 'socrefs',\n",
    " 'family',\n",
    " 'friend',\n",
    " 'female',\n",
    " 'male',\n",
    " 'Culture',\n",
    " 'politic',\n",
    " 'ethnicity',\n",
    " 'tech',\n",
    " 'Lifestyle',\n",
    " 'leisure',\n",
    " 'home',\n",
    " 'work',\n",
    " 'money',\n",
    " 'relig',\n",
    " 'Physical',\n",
    " 'health',\n",
    " 'illness',\n",
    " 'wellness',\n",
    " 'mental',\n",
    " 'substances',\n",
    " 'sexual',\n",
    " 'food',\n",
    " 'death',\n",
    " 'need',\n",
    " 'want',\n",
    " 'acquire',\n",
    " 'lack',\n",
    " 'fulfill',\n",
    " 'fatigue',\n",
    " 'reward',\n",
    " 'risk',\n",
    " 'curiosity',\n",
    " 'allure',\n",
    " 'Perception',\n",
    " 'attention',\n",
    " 'motion',\n",
    " 'space',\n",
    " 'visual',\n",
    " 'auditory',\n",
    " 'feeling',\n",
    " 'time',\n",
    " 'focuspast',\n",
    " 'focuspresent',\n",
    " 'focusfuture',\n",
    " 'Conversation',\n",
    " 'netspeak',\n",
    " 'assent',\n",
    " 'nonflu',\n",
    " 'filler']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fb2aee-780c-4a33-8370-9c99ce213e2b",
   "metadata": {},
   "source": [
    "# Skip loading data and extracting featues and load below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e21c14-ccae-4f6f-bfc7-740d3fd207e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Or load data and extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1dc4d6-bbb8-4ddf-b407-6411b8b6101c",
   "metadata": {},
   "source": [
    "# Load everything above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883ec0a-0b68-48f8-894f-36c45fa71e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "run_this = False #True saves, False loads\n",
    "if run_this:\n",
    "    with open(f'./data/input/ctl/ctl_dfs_features_{task}.pkl', 'wb') as f:\n",
    "        pickle.dump(dfs, f) \n",
    "else:\n",
    "\n",
    "    with open(f'./data/input/ctl/ctl_dfs_features_{task}.pkl', 'rb') as f:\n",
    "    \tdfs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1623df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from srl_constructs import constructs_in_order\n",
    "\n",
    "\n",
    "def get_splits(feature_vector):\n",
    "\tif feature_vector in ['tfidf']:\n",
    "\t\tX_train = dfs['train']['X'] # text\n",
    "\t\t# X_val = dfs['val']['X']\n",
    "\t\tX_test = dfs['test']['X']\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\t# y_val = dfs['val']['y']\n",
    "\t\ty_test = dfs['test']['y']\n",
    "\t\t\n",
    "\telif feature_vector in ['liwc22']:        \n",
    "\t\t\n",
    "\t\tX_train = dfs['train']['liwc22_X'] \n",
    "\t\t# X_val = dfs['val']['liwc22_X']    \n",
    "\t\tX_test = dfs['test']['liwc22_X']\n",
    "\t\ty_train = dfs['train']['liwc22_y']\n",
    "\t\t# y_val = dfs['val']['liwc22_y']\n",
    "\t\ty_test = dfs['test']['liwc22_y']\n",
    "\n",
    "\telif feature_vector in ['srl_unvalidated']:        \n",
    "\t\t\n",
    "\t\tX_train = dfs['train']['srl_unvalidated'] \n",
    "\t\t# X_val = dfs['val']['srl_unvalidated']    \n",
    "\t\tX_test = dfs['test']['srl_unvalidated']\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\t# y_val = dfs['val']['y'] \n",
    "\t\ty_test = dfs['test']['y']\n",
    "\n",
    "\telif feature_vector in ['SRL GPT-4 Turbo']:\n",
    "\t\tX_train = dfs['train']['SRL GPT-4 Turbo'][constructs_in_order] \n",
    "\t\t# X_val = dfs['val']['SRL GPT-4 Turbo'][constructs_in_order]    \n",
    "\t\tX_test = dfs['test']['SRL GPT-4 Turbo'][constructs_in_order]\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\t# y_val = dfs['val']['y'] \n",
    "\t\ty_test = dfs['test']['y']\n",
    "\t\t\n",
    "\n",
    "\telif feature_vector in ['text_descriptives']:        \n",
    "\t\t\n",
    "\t\tX_train = dfs['train']['text_descriptives'] \n",
    "\t\tX_test = dfs['test']['text_descriptives']\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\ty_test = dfs['test']['y']\n",
    "\t\t\n",
    "\telif feature_vector in ['srl_unvalidated_text_descriptives']:        \n",
    "\t\t\n",
    "\t\tX_train = dfs['train']['srl_unvalidated_text_descriptives'] \n",
    "\t\tX_test = dfs['test']['srl_unvalidated_text_descriptives']\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\ty_test = dfs['test']['y']\n",
    "\t\n",
    "\n",
    "\t\n",
    "\telif feature_vector in ['all-MiniLM-L6-v2']:\n",
    "\t\tX_train = dfs['train']['all-MiniLM-L6-v2'] \n",
    "\t\t# X_val = dfs['val']['all-MiniLM-L6-v2']    \n",
    "\t\tX_test = dfs['test']['all-MiniLM-L6-v2']\n",
    "\t\ty_train = dfs['train']['y']\n",
    "\t\t# y_val = dfs['val']['y']\n",
    "\t\ty_test = dfs['test']['y']\n",
    "\t\t\n",
    "\t\n",
    "\treturn X_train, y_train,X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4089567c",
   "metadata": {},
   "source": [
    "# Clean up results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facfdc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_empty_row(df, index_to_insert):\n",
    "\t# Splitting the DataFrame\n",
    "\tdf_before = df.iloc[:index_to_insert, :]\n",
    "\tdf_after = df.iloc[index_to_insert:, :]\n",
    "\n",
    "\t# Creating an empty row (all values set to NaN or any desired value)\n",
    "\t# The length of the empty DataFrame should match the number of columns in the original DataFrame\n",
    "\tempty_row = pd.DataFrame({col: np.nan for col in df.columns}, index=[index_to_insert])\n",
    "\n",
    "\t# Adjusting the index for df_after to accommodate the new row\n",
    "\tdf_after.index = df_after.index + 1\n",
    "\n",
    "\t# Concatenating the DataFrames\n",
    "\tdf_updated = pd.concat([df_before, empty_row, df_after])\n",
    "\n",
    "\t# Resetting the index if desired\n",
    "\tdf_updated = df_updated.reset_index(drop=True)\n",
    "\treturn df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05b6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sizes = ['all', 150] # TODO\n",
    "model_names = ['LGBMRegressor', 'Ridge']\n",
    "timestamp = '24-02-16T06-25-10'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "metrics_to_keep = ['Features','Macro avg. RMSE','RMSE per value', 'RMSE', 'rho']\n",
    "feature_vectors_clean = {\n",
    "\t\t\t\t\t\t 'liwc22_semantic':\"LIWC-22 only semantic (85)\",\n",
    "\t\t\t\t\t\t 'liwc22':\"LIWC-22 (117)\",\n",
    "\t\t\t\t\t\t \"SRL GPT-4 Turbo\": \"SRL GPT-4 (49)\",\n",
    "\t\t\t\t\t\t \"srl_unvalidated\": \"SRL GPT-4 + manual (49)\",\n",
    "\t\t\t\t\t\t \"srl_validated\": \"SRL GPT-4 + manual + clinicians (49)\",\n",
    "\t\t\t\t\t\t#  \"text_descriptives\": \"Linguistic (N)\",\n",
    "\t\t\t\t\t\t#  \"SRL GPT-4 Turbo_text_descriptives\": \"SRL GPT-4 + others (N)\",\n",
    "\t\t\t\t\t\t#  \"srl_unvalidated_text_descriptives\": \"SRL unvalidated + linguistic (N)\",\n",
    "\t\t\t\t\t\t#  \"srl_validated_text_descriptives\": \"SRL validated + linguistic (N)\",\n",
    "\t\t\t\t\t\t \"all-MiniLM-L6-v2\": \"all-MiniLM-L6-v2 (384)\",\n",
    "\t\t\t\t\t\t \"RoBERTa\":'RoBERTa (768)'}\n",
    "\n",
    "for n in sample_sizes:\n",
    "\tprint(n)\n",
    "\t\n",
    "\tfor model in model_names:\t\n",
    "\t\tprint(model)\n",
    "\t\tresults_df = []\n",
    "\t\t\n",
    "\t\tresults_dir = f'results_{timestamp}_{n}_regression_{balance_values[-1]}/'\n",
    "\t\t\n",
    "\t\tfiles = os.listdir('./data/output/ml_performance/'+results_dir)\n",
    "\t\t\n",
    "\t\tfor feature in feature_vectors_clean.keys():\n",
    "\n",
    "\t\t\tfile = [n for n in files if  f\"results_{feature}_{model}\" in n and 'csv' in n]\n",
    "\t\t\tif file != []:\n",
    "\t\t\t\t\n",
    "\t\t\t\tresults_df.append(pd.read_csv('./data/output/ml_performance/'+results_dir+file[0]))\n",
    "\t\t\t\t# display(pd.read_csv('./data/output/ml_performance/'+results_dir+file[0]))\n",
    "\t\t\t\t\n",
    "\t\t\t# else:\n",
    "\t\t\t# \tempty_df  =pd.DataFrame([feature]+[np.nan]*len(metrics_to_keep[1:])).T\n",
    "\t\t\t# \tempty_df.columns = metrics_to_keep\n",
    "\t\t\t# \tresults_df.append(empty_df)\n",
    "\n",
    "\n",
    "\t\t\t\n",
    "\n",
    "\t\tresults_df = pd.concat(results_df)\n",
    "\t\t# results_df = pd.read_csv('./data/output/ml_performance/'+results_dir+f'results_{n}_{timestamp}.csv')\n",
    "\t\tresults_df = results_df[results_df['Estimator'].str.contains(model)]\n",
    "\t\tresults_df.reset_index(drop=True,inplace=True)\n",
    "\t\t# results_df = results_df.drop(['n','Estimator',  'gridsearch', 'Best parameters', 'y_train_min', 'y_train_max', 'R^2', 'r', 'MAE','Macro avg. MAE', 'MAE per value'], axis = 1)\n",
    "\t\tresults_df = results_df[metrics_to_keep]\n",
    "\t\tresults_df['Features'] = results_df['Features'].map(feature_vectors_clean)\n",
    "\t\tfeature_vectors_clean.keys()\n",
    "\n",
    "\n",
    "\n",
    "\t\t\n",
    "\t\tresults_df = insert_empty_row(results_df, 5)\n",
    "\t\tresults_df = insert_empty_row(results_df, 6)\n",
    "\t\tresults_df = results_df.rename(columns={'Features':'Model (n features)'})\n",
    "\t\tresults_df ['Macro avg. RMSE'] = [f\"{n} {i}\" for n, i in zip(results_df ['Macro avg. RMSE'], results_df ['RMSE per value'])]\n",
    "\t\tresults_df = results_df.drop(['RMSE per value'], axis = 1)\n",
    "\t\t\n",
    "\n",
    "\t\tdisplay(results_df)\n",
    "\t\tresults_df.to_csv(f'./data/output/tables/'+f'results_{model}_{n}.csv', index=False)\n",
    "\t\t\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a00614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "feature_vectors = ['liwc22_semantic', 'srl_unvalidated','all-MiniLM-L6-v2']\n",
    "timestamp = '24-02-16T06-25-10'\n",
    "\n",
    "model_name = 'LGBMRegressor'\n",
    "\n",
    "toy = False\n",
    "\n",
    "for plot_type in ['strip']:\n",
    "\n",
    "\tfor feature_vector in feature_vectors:\t\n",
    "\t\tprint(model)\n",
    "\t\tresults_df = []\n",
    "\t\t\n",
    "\t\tresults_dir = f'results_{timestamp}_{n}_regression_{balance_values[-1]}/'\n",
    "\t\t\n",
    "\t\tfiles = os.listdir('./data/output/ml_performance/'+results_dir)\n",
    "\t\t\n",
    "\n",
    "\t\tprint(model)\n",
    "\t\tfile = [n for n in files if  f\"y_pred_{feature_vector}_{model_name}\" in n and 'csv' in n]\n",
    "\t\tif file != []:\n",
    "\t\t\tif len(file)==1:\t\n",
    "\t\t\t\ty_pred = pd.read_csv('./data/output/ml_performance/'+results_dir+file[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\tif feature_vector == 'liwc22_semantic':\n",
    "\t\t\ty_test = dfs['test']['liwc22_y']\n",
    "\t\telse:\n",
    "\t\t\tX_train, y_train, X_test, y_test = get_splits(feature_vector)\n",
    "\n",
    "\n",
    "\t\ty_df = y_pred.copy()\n",
    "\t\ti = 2\n",
    "\t\ty_df['y_test'] = y_test\n",
    "\t\ty_df.columns = ['Predictions', 'True scores']\n",
    "\n",
    "\t\tif toy:\n",
    "\t\t\ty_df = y_df.sample(frac=0.20)\n",
    "\n",
    "\n",
    "\t\t# colorblind friendly https://davidmathlogic.com/colorblind/#%23648FFF-%23785EF0-%23DC267F-%23FE6100-%23FFB000\n",
    "\t\t\t\n",
    "\t\t\n",
    "\n",
    "\t\t\t\n",
    "\t\tcolors_severity = {\n",
    "\t\t\t\n",
    "\t\t\t1: '#FFB000',\n",
    "\t\t\t2: '#FE6100',\n",
    "\t\t\t3: '#DC267F',\n",
    "\t\t\t# 1: '#FFBB78',\n",
    "\t\t\t# 2: '#FF7F0E',\n",
    "\t\t\t# 3: '#D62728' \n",
    "\t\t\t\n",
    "\t\t}\n",
    "\n",
    "\t\t# Create a boxplot with the specified color palette\n",
    "\t\t\n",
    "\t\ttoy\n",
    "\t\tfigsize = (3.25,8)\n",
    "\t\tplt.figure(figsize=figsize)  # Width=10 inches, Height=6 inches\n",
    "\t\t# sns.scatterplot(data = y_df, y = 'y_pred',x = 'y_test', alpha = 0.1)\n",
    "\n",
    "\n",
    "\t\tsns.boxplot(y='Predictions', x='True scores', data=y_df, palette=colors_severity, showfliers=False,\n",
    "\t\t\t  boxprops=dict(alpha=1))\n",
    "\n",
    "\t\tif plot_type == 'swarm':\n",
    "\t\t\tsns.swarmplot(y='Predictions', x='True scores', data=y_df,  color='0.25', alpha=0.3)\n",
    "\t\telif plot_type == 'strip':\n",
    "\t\t\tsns.stripplot(y='Predictions', x='True scores', data=y_df,  color='#648FFF', alpha=0.2,jitter=0.2)\n",
    "\n",
    "\t\tplt.xticks(ticks = [0,1,2],labels = ['Nonsuicidal', 'Suicidal', 'Imminent risk'])\n",
    "\t\tplt.ylim((0.4,3.5))\n",
    "\n",
    "\n",
    "\t\t# Show the plot\n",
    "\t\t\n",
    "\t\tplt.tight_layout()\n",
    "\t\tplt.savefig(f'./data/output/figures/{plot_type}_boxplot_{feature_vector}_{model_name}.png', bbox_inches='tight', dpi=300)\n",
    "\t\tplt.show()\n",
    "\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a6a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b0643-e035-40a7-9b1a-b414fbf7f2cf",
   "metadata": {},
   "source": [
    "# Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'./data/input/ctl/ctl_dfs_features_{task}.pkl', 'rb') as f:\n",
    "\tdfs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6fa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'LGBMRegressor'\n",
    "n = 'all'\n",
    "\n",
    "\n",
    "results_dir = f'./data/output/ml_performance/results_{timestamp}_{n}_regression_{balance_values[-1]}/'\n",
    "\n",
    "files = os.listdir(results_dir)\n",
    "feature_vectors = ['srl_unvalidated', 'liwc22_semantic']\n",
    "table_names = ['SRL GPT-4 + manual', 'LIWC-22 semantic']\n",
    "\n",
    "rank_col_name = 'Rank'\n",
    "files\n",
    "feature_importance = []\n",
    "for file, table_name in zip(feature_vectors, table_names):\n",
    "    file1 = [n for n in files if ('feature_importance_'+file in n and 'clean' not in n)][0]\n",
    "    \n",
    "print(file1)\n",
    "fi = pd.read_csv(results_dir+file1)\n",
    "# fi.columns = ['Feature', 'Split', 'Gain']\n",
    "# fi=fi.drop('Split', axis=1).round(1)\n",
    "# fi = fi.reset_index()\n",
    "# fi.columns = [rank_col_name, 'Feature', 'Gain']\n",
    "# fi[rank_col_name]+=1\n",
    "# fi[rank_col_name] = fi[rank_col_name].astype(str)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each feature, correlate feature with y\n",
    "from scipy.stats import spearmanr\n",
    "import math\n",
    "liwc22_X = dfs['train']['liwc22_X']\n",
    "liwc22_y = dfs['train']['liwc22_y']\n",
    "liwc_rho = {}\n",
    "for feature in liwc22_X.columns:\n",
    "\tfiltered_list1, filtered_list2 = zip(*[(x, y) for x, y in zip(liwc22_y, liwc22_X[feature].values) if not math.isnan(x) and not math.isnan(y)])\n",
    "\n",
    "\t# Converting the tuples back to lists\n",
    "\tfiltered_list1 = list(filtered_list1)\n",
    "\tfiltered_list2 = list(filtered_list2)\n",
    "\tr,p = spearmanr(filtered_list1, filtered_list2)\n",
    "\t# r,p = spearmanr(liwc22_y, liwc22_X[feature])\n",
    "\t# if p <= 0.05:\n",
    "\tliwc_rho[feature] = np.round(r,2)\n",
    "\tif str(r)=='nan':\n",
    "\t\t\n",
    "\t\tprint(feature)\n",
    "\t# else:\n",
    "\t\t# liwc_rho[feature] = np.nan\n",
    "\n",
    "\n",
    "# For each feature, correlate feature with y\n",
    "srl_unv_X = dfs['train']['srl_unvalidated']\n",
    "srl_unv_y = dfs['train']['y']\n",
    "srl_unv_rho = {}\n",
    "for feature in srl_unv_X.columns:\n",
    "\t# remove nans:\n",
    "\tfiltered_list1, filtered_list2 = zip(*[(x, y) for x, y in zip(srl_unv_y, srl_unv_X[feature].values) if not math.isnan(x) and not math.isnan(y)])\n",
    "\n",
    "\t# Converting the tuples back to lists\n",
    "\tfiltered_list1 = list(filtered_list1)\n",
    "\tfiltered_list2 = list(filtered_list2)\n",
    "\tr,p = spearmanr(filtered_list1, filtered_list2)\n",
    "\t# if p <= 0.05:\n",
    "\tsrl_unv_rho[feature] = np.round(r,2)\n",
    "\t# else:\n",
    "\t\t# srl_unv_rho[feature] = np.nan\n",
    "\t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ae094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db7913-34df-437d-86f8-8a263c11e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'LGBMRegressor'\n",
    "files = os.listdir(results_dir)\n",
    "feature_vectors = ['srl_unvalidated', 'liwc22_semantic']\n",
    "table_names = ['SRL unvalidated', 'LIWC-22 semantic']\n",
    "\n",
    "rank_col_name = 'Rank'\n",
    "files\n",
    "feature_importance = []\n",
    "for file, table_name in zip(feature_vectors, table_names):\n",
    "\t# timestamp_i = timestamp.replace('results_', '')\n",
    "\t# if file == 'liwc22_semantic':\n",
    "\t# \tfile1 = f'feature_importance_{file}_{model}_gridsearch-True_all_24-02-16T00-03-59.csv'\n",
    "\t# else:\n",
    "\tfile1 = f'feature_importance_{file}_{model}_gridsearch-True_all_{timestamp}.csv'\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\tfi = pd.read_csv(results_dir+file1)\n",
    "\tfi.columns = ['Feature', 'Split', 'Gain']\n",
    "\tfi=fi.drop('Split', axis=1).round(1)\n",
    "\tfi = fi.reset_index()\n",
    "\tfi.columns = [rank_col_name, 'Feature', 'Gain']\n",
    "\tfi[rank_col_name]+=1\n",
    "\tfi[rank_col_name] = fi[rank_col_name].astype(str)\n",
    "\tif 'liwc22' in file:\n",
    "\t\tfi['rho'] = fi['Feature'].map(liwc_rho)\n",
    "\telse:\n",
    "\t\tfi['rho'] = fi['Feature'].map(srl_unv_rho)\n",
    "\n",
    "\tfi.to_csv(results_dir+'feature_importance_'+file+'_clean.csv', index=False)\n",
    "\tcolumns = pd.MultiIndex.from_tuples([\n",
    "\t(table_name, rank_col_name),\n",
    "\t(table_name, 'Feature'),\n",
    "\t(table_name, 'Gain'),\n",
    "\t(table_name, 'rho'),\n",
    "\t])\n",
    "\tfi.columns = columns\n",
    "\tfeature_importance.append(fi)\n",
    "\n",
    "feature_importance_df = pd.concat([feature_importance[0],feature_importance[1].drop(columns=(table_names[1], rank_col_name))],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "feature_vectors = '_'.join(feature_vectors)\n",
    "\n",
    "\n",
    "\n",
    "feature_importance_df.to_csv(results_dir+f'feature_importance_{feature_vectors}_gridsearch-True_all_{timestamp}_all.csv', index= 0 )\n",
    "feature_importance_df.to_csv('./data/output/tables/'+f'feature_importance_{feature_vectors}_gridsearch-True_all_{timestamp}_all.csv', index= 0 )\n",
    "\n",
    "display(feature_importance_df)\n",
    "\n",
    "feature_importance_df.iloc[:20].to_csv(results_dir+f'feature_importance_{feature_vectors}_gridsearch-True_all_{timestamp}_top20.csv', index= 0 )\n",
    "\n",
    "# top 15 and bottom 10\n",
    "df0 = feature_importance[0].copy()\n",
    "top_15 = df0.head(15)\n",
    "bottom_10 = df0.tail(10)\n",
    "empty_row = pd.DataFrame(np.nan, index=[0], columns=bottom_10.columns)\n",
    "bottom_10 = pd.concat([empty_row, bottom_10]).reset_index(drop=True)\n",
    "df0 = pd.concat([top_15, bottom_10])\n",
    "df0 = df0.reset_index(drop=True)\n",
    "\n",
    "df1 = feature_importance[1].copy()\n",
    "top_15 = df1.head(15)\n",
    "bottom_10 = df1.tail(10)\n",
    "empty_row = pd.DataFrame(np.nan, index=[0], columns=bottom_10.columns)\n",
    "bottom_10 = pd.concat([empty_row, bottom_10]).reset_index(drop=True)\n",
    "df1 = pd.concat([top_15, bottom_10])\n",
    "df1 = df1.reset_index(drop=True)\n",
    "\n",
    "\n",
    "feature_importance_df = pd.concat([df0,df1],axis=1)\n",
    "feature_importance_df.to_csv('./data/output/tables/'+f'feature_importance_{feature_vectors}_gridsearch-True_all_{timestamp}_top_and_bottom.csv', index= 0 )\n",
    "display(feature_importance_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e3912-5348-4f0a-ad7c-627395a6504e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc38a80a-4a11-459a-b950-109d9cce2283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109390c1-962e-4e0c-829c-4972718635c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af23ab6-fcd9-47da-a768-7954c397b65c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1150cf-cdc6-48c3-8cbc-41bfc85512c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dd6058-5907-4068-9759-719a1bc5dad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ef5895b",
   "metadata": {},
   "source": [
    "# Error analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dde7a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_i = '24-02-15T20-17-48'\n",
    "n = 'all'\n",
    "\n",
    "output_dir_i = output_dir + f'results_{ts_i}_{n}_{task}_{balance_values[-1]}/'\n",
    "\n",
    "results = []\n",
    "# for gridsearch in [True]:\n",
    "\n",
    "# for feature_vector in ['srl_unvalidated', 'all-MiniLM-L6-v2']:#['srl_unvalidated']:#, 'srl_unvalidated']:\n",
    "for feature_vector in feature_vectors:#['srl_unvalidated']:#, 'srl_unvalidated']:\n",
    "\tif feature_vector == 'liwc22_semantic':\n",
    "\t\tX_train, y_train,X_val, y_val, X_test, y_test = get_splits('liwc22')\n",
    "\t\tX_train = X_train[liwc_semantic]\n",
    "\t\tX_val = X_val[liwc_semantic]\n",
    "\t\tX_test = X_test[liwc_semantic]\n",
    "\n",
    "\telse:\n",
    "\t\tX_train, y_train,X_val, y_val, X_test, y_test = get_splits(feature_vector)\n",
    "\n",
    "\t\n",
    "\n",
    "\n",
    "\tif toy:\n",
    "\t\tX_train['y'] = y_train\n",
    "\t\tX_train = X_train.sample(n = 100)\n",
    "\t\ty_train = X_train['y'].values\n",
    "\t\tX_train = X_train.drop('y', axis=1)\n",
    "\n",
    "\telif n!='all':\n",
    "\t\tX_train['y'] = y_train\n",
    "\t\tX_train = X_train.sample(n = n, random_state=42)\n",
    "\t\ty_train = X_train['y'].values\n",
    "\t\tX_train = X_train.drop('y', axis=1)\n",
    "\n",
    "\n",
    "\tif task == 'classification':\n",
    "\t\tencoder = LabelEncoder()\n",
    "\n",
    "\t\t# Fit and transform the labels to integers\n",
    "\t\ty_train = encoder.fit_transform(y_train)\n",
    "\t\ty_test = encoder.transform(y_test)\n",
    "\n",
    "\t\n",
    "\tfor model_name in model_names: \n",
    "\t\ty_pred = pd.read_csv(output_dir_i+f'y_pred_{feature_vector}_{model_name}_gridsearch-{gridsearch}_{n}_{ts_i}.csv')\n",
    "\t\tbreak\n",
    "\tbreak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d69594",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "y_df = y_pred.copy()\n",
    "i = 2\n",
    "y_df['y_test'] = y_test\n",
    "y_df.columns = ['y_pred', 'y_test']\n",
    "y_df_i = y_df[y_df['y_test']==i]\n",
    "y_df_i['error'] = y_df_i['y_pred'] - y_df_i['y_test']\n",
    "y_df_i = y_df_i.sort_values(by='error')\n",
    "X_test_text = dfs['test']['df_text']\n",
    "print(X_test_text.shape, y_df.shape)\n",
    "# display(X_test_text.head(), y_df[:5])\n",
    "display(y_df_i.iloc[:10])\n",
    "display(X_test_text.loc[y_df_i.index[:10]])\n",
    "docs = X_test_text.loc[y_df_i.index[:10]]['text'].to_list()\n",
    "\n",
    "print(docs)\n",
    "# metrics.mean_absolute_error(y_test, y_pred.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a98d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "sys.path.append( './../../concept-tracker/') # TODO: replace with pip install construct-tracker\n",
    "from concept_tracker import lexicon\n",
    "\n",
    "\n",
    "def load_lexicon(path):\n",
    "\tlexicon = dill.load(open(path, \"rb\"))\n",
    "\treturn lexicon\n",
    "srl = load_lexicon(\"./data/input/lexicons/suicide_risk_lexicon_calibrated_unmatched_tokens_unvalidated_24-02-15T19-30-52.pickle\")\n",
    "\n",
    "\n",
    "feature_vectors, matches_counter_d, matches_per_doc, matches_per_construct  = lexicon.extract(docs,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tsrl.constructs,normalize = normalize_lexicon, return_matches=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tadd_lemmatized_lexicon=True, lemmatize_docs=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\texact_match_n = srl.exact_match_n,exact_match_tokens = srl.exact_match_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2175d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "print(docs[i])\n",
    "constructs_alphabetical = constructs_in_order.copy()\n",
    "constructs_alphabetical.sort()\n",
    "pd.DataFrame(matches_per_doc[i])[constructs_alphabetical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf8a35-3aa5-4211-a30c-200a6fa1d9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
