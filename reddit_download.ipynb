{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for similar reddits here:\n",
    "https://anvaka.github.io/sayit/?query=GriefSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 6000\n",
    "\n",
    "subreddits = {\n",
    "'self_harm': 'selfharm',\n",
    "'suicide': 'SuicideWatch',\n",
    "'bully': 'bullying',\n",
    "'abuse_physical': 'abusesurvivors',\n",
    "'abuse_sexual': 'sexualassault',\n",
    "'relationship': 'relationship_advice',\n",
    "'bereavement': 'GriefSupport',\n",
    "'isolated': 'lonely',\n",
    "'anxiety': 'Anxiety',\n",
    "'depressed': 'depression',\n",
    "'gender': 'askLGBT', # chosen over LGBT because the latter is more memes support seeking\n",
    "'eating': 'EatingDisorders',\n",
    "'substance': 'addiction'\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import time\n",
    "from typing import List, Optional\n",
    "import api_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = {'self_harm': 'selfharm',\n",
    " 'suicide': 'SuicideWatch',\n",
    " 'bully': 'bullying',\n",
    " 'abuse_physical': 'abusesurvivors',\n",
    " 'abuse_sexual': 'sexualassault',\n",
    " 'relationship': 'relationship_advice',\n",
    " 'bereavement': 'GriefSupport',\n",
    " 'isolated': 'lonely',\n",
    " 'anxiety': 'Anxiety',\n",
    " 'depressed': 'depression',\n",
    " 'gender': 'AskLGBT',\n",
    " 'eating': 'EatingDisorders',\n",
    " 'substance': 'addiction'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime as dt  # Import as dt to avoid confusion\n",
    "from typing import List, Dict, Set, Optional\n",
    "\n",
    "class RedditSampler:\n",
    "    def __init__(self, client_id: str, client_secret: str, user_agent: str):\n",
    "        self.reddit = praw.Reddit(\n",
    "            client_id=client_id,\n",
    "            client_secret=client_secret,\n",
    "            user_agent=user_agent\n",
    "        )\n",
    "\n",
    "    def get_samples(\n",
    "        self,\n",
    "        subreddits: List[str],\n",
    "        sample_size: int = 6000,\n",
    "        sleep_amount: float = 0.1,\n",
    "        submission_type: str = \"all\",\n",
    "        existing_data: Optional[pd.DataFrame] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        all_submissions = []\n",
    "        \n",
    "        # Create a dictionary to track existing post IDs per subreddit\n",
    "        existing_ids = {}\n",
    "        if existing_data is not None:\n",
    "            for subreddit in subreddits:\n",
    "                # Get all post IDs for this subreddit from existing data\n",
    "                sub_data = existing_data[existing_data['subreddit'] == subreddit]\n",
    "                existing_ids[subreddit] = set(sub_data['id'].unique())\n",
    "                \n",
    "                # Print stats about existing data\n",
    "                print(f\"Found {len(existing_ids[subreddit])} existing posts for r/{subreddit}\")\n",
    "        else:\n",
    "            # Initialize empty sets if no existing data\n",
    "            for subreddit in subreddits:\n",
    "                existing_ids[subreddit] = set()\n",
    "        \n",
    "        # Sort methods prioritized to get more varied content\n",
    "        sorts = ['top', 'controversial', 'hot', 'new']  # Changed order to prefer older posts\n",
    "        time_filters = ['all', 'year', 'month', 'week', 'day']  # Added 'day' for more granularity\n",
    "        \n",
    "        # For each subreddit, track which post IDs we've already tried to use as \"before\" markers\n",
    "        # to avoid getting stuck in the same posts\n",
    "        used_before_ids = {subreddit: set() for subreddit in subreddits}\n",
    "        \n",
    "        for subreddit_name in subreddits:\n",
    "            try:\n",
    "                # Calculate how many more posts we need\n",
    "                needed_posts = sample_size - len(existing_ids[subreddit_name])\n",
    "                \n",
    "                if needed_posts <= 0:\n",
    "                    print(f\"Already have enough posts for r/{subreddit_name}, skipping\")\n",
    "                    # Add existing posts to output\n",
    "                    if existing_data is not None:\n",
    "                        sub_data = existing_data[existing_data['subreddit'] == subreddit_name]\n",
    "                        all_submissions.extend(sub_data.to_dict('records'))\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Need to collect {needed_posts} more posts for r/{subreddit_name}\")\n",
    "                \n",
    "                subreddit = self.reddit.subreddit(subreddit_name)\n",
    "                sub_samples = set()  # Using set to avoid duplicates\n",
    "                \n",
    "                for sort in sorts:\n",
    "                    if len(sub_samples) >= needed_posts:\n",
    "                        break\n",
    "                        \n",
    "                    for time_filter in time_filters:\n",
    "                        if len(sub_samples) >= needed_posts:\n",
    "                            break\n",
    "                            \n",
    "                        try:\n",
    "                            # Different handling based on sort method\n",
    "                            if sort == 'new':\n",
    "                                submissions = subreddit.new(limit=1000)\n",
    "                            elif sort == 'hot':\n",
    "                                submissions = subreddit.hot(limit=1000)\n",
    "                            else:\n",
    "                                # Make sure the method exists before trying to use it\n",
    "                                method = getattr(subreddit, sort, None)\n",
    "                                if method is None:\n",
    "                                    print(f\"Warning: Method '{sort}' not found on subreddit object\")\n",
    "                                    continue\n",
    "                                    \n",
    "                                # Use before_id parameter to get older posts if available in existing_ids\n",
    "                                if existing_ids[subreddit_name] and len(existing_ids[subreddit_name]) > 0:\n",
    "                                    # Get potential IDs from existing data, filtering out ones we've already tried\n",
    "                                    candidate_ids = [id for id in existing_ids[subreddit_name] \n",
    "                                                   if id not in used_before_ids[subreddit_name]]\n",
    "                                    \n",
    "                                    # If we have no unused IDs, reset and try again\n",
    "                                    if not candidate_ids:\n",
    "                                        print(f\"Resetting used before IDs for {subreddit_name}\")\n",
    "                                        used_before_ids[subreddit_name].clear()\n",
    "                                        candidate_ids = list(existing_ids[subreddit_name])\n",
    "                                    \n",
    "                                    # Select a random ID to use as the \"before\" parameter\n",
    "                                    random_id = random.choice(candidate_ids)\n",
    "                                    used_before_ids[subreddit_name].add(random_id)\n",
    "                                    \n",
    "                                    try:\n",
    "                                        # For new posts, we use \"before\" parameter\n",
    "                                        if sort == 'new':\n",
    "                                            submissions = subreddit.new(limit=1000, before=f\"t3_{random_id}\")\n",
    "                                        # For other sorting methods, we try using \"before\"\n",
    "                                        else:\n",
    "                                            submissions = method(time_filter=time_filter, limit=1000, params={\"before\": f\"t3_{random_id}\"})\n",
    "                                        \n",
    "                                        print(f\"Using before_id={random_id} to get older posts for {sort}/{time_filter}\")\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error using before parameter: {str(e)}\")\n",
    "                                        # Fall back to standard method\n",
    "                                        submissions = method(time_filter=time_filter, limit=1000)\n",
    "                                else:\n",
    "                                    submissions = method(time_filter=time_filter, limit=1000)\n",
    "                            \n",
    "                            for submission in submissions:\n",
    "                                                # Skip if we already have this post\n",
    "                                if submission.id in existing_ids[subreddit_name]:\n",
    "                                    # Print debug info occasionally \n",
    "                                    if random.random() < 0.01:  # 1% chance to print\n",
    "                                        print(f\"Skipping already seen post {submission.id}\")\n",
    "                                    continue\n",
    "                                    \n",
    "                                if len(sub_samples) >= needed_posts:\n",
    "                                    break\n",
    "                                    \n",
    "                                if submission_type != \"all\":\n",
    "                                    if submission_type == \"self\" and not submission.is_self:\n",
    "                                        continue\n",
    "                                    if submission_type == \"link\" and submission.is_self:\n",
    "                                        continue\n",
    "                                \n",
    "                                # Create dictionary with submission data\n",
    "                                sub_dict = {\n",
    "                                    'subreddit': subreddit_name,\n",
    "                                    'id': submission.id,\n",
    "                                    'title': submission.title,\n",
    "                                    'author': str(submission.author),\n",
    "                                    'created_utc': dt.fromtimestamp(submission.created_utc),\n",
    "                                    'score': submission.score,\n",
    "                                    'upvote_ratio': submission.upvote_ratio,\n",
    "                                    'num_comments': submission.num_comments,\n",
    "                                    'url': submission.url,\n",
    "                                    'is_self': submission.is_self,\n",
    "                                    'selftext': submission.selftext if submission.is_self else None,\n",
    "                                    'sort_method': sort,\n",
    "                                    'time_filter': time_filter if sort != 'new' and sort != 'hot' else None\n",
    "                                }\n",
    "                                \n",
    "                                # Add to our collection and track the ID\n",
    "                                sub_dict_tuple = tuple(sorted(sub_dict.items()))\n",
    "                                sub_samples.add(sub_dict_tuple)\n",
    "                                existing_ids[subreddit_name].add(submission.id)\n",
    "                                \n",
    "                                time.sleep(sleep_amount)\n",
    "                                \n",
    "                            print(f\"Collected {len(sub_samples)} samples from r/{subreddit_name} ({sort}/{time_filter})\")\n",
    "                            time.sleep(1)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error with {sort}/{time_filter}: {str(e)}\")\n",
    "                            continue\n",
    "                \n",
    "                # Convert back to list of dicts\n",
    "                sub_samples_list = [dict(items) for items in sub_samples]\n",
    "                \n",
    "                # Add to all submissions\n",
    "                all_submissions.extend(sub_samples_list)\n",
    "                \n",
    "                # Also add existing submissions for this subreddit if provided\n",
    "                if existing_data is not None:\n",
    "                    sub_existing = existing_data[existing_data['subreddit'] == subreddit_name]\n",
    "                    all_submissions.extend(sub_existing.to_dict('records'))\n",
    "                \n",
    "                # If we couldn't get any new samples but we need more, try a different approach\n",
    "                if len(sub_samples) == 0 and needed_posts > 0:\n",
    "                    print(f\"Couldn't get any new posts for {subreddit_name}, trying direct PRAW approach...\")\n",
    "                    \n",
    "                    # Try getting posts with specific PRAW parameters\n",
    "                    try:\n",
    "                        # This approach gets posts directly by time period (newest to oldest)\n",
    "                        for days_ago in range(30, 365, 30):  # Try different time periods\n",
    "                            if len(sub_samples) >= needed_posts:\n",
    "                                break\n",
    "                                \n",
    "                            end_time = dt.now().timestamp() - (days_ago * 24 * 60 * 60)\n",
    "                            start_time = end_time - (30 * 24 * 60 * 60)\n",
    "                            \n",
    "                            print(f\"Trying time period: {days_ago-30} to {days_ago} days ago\")\n",
    "                            \n",
    "                            # Use PRAW search to find posts in that time period\n",
    "                            search_results = subreddit.search(\n",
    "                                \"timestamp:{}..{}\".format(int(start_time), int(end_time)),\n",
    "                                sort=\"new\", \n",
    "                                limit=200\n",
    "                            )\n",
    "                            \n",
    "                            for submission in search_results:\n",
    "                                if submission.id in existing_ids[subreddit_name]:\n",
    "                                    continue\n",
    "                                    \n",
    "                                if len(sub_samples) >= needed_posts:\n",
    "                                    break\n",
    "                                \n",
    "                                if submission_type != \"all\":\n",
    "                                    if submission_type == \"self\" and not submission.is_self:\n",
    "                                        continue\n",
    "                                    if submission_type == \"link\" and submission.is_self:\n",
    "                                        continue\n",
    "                                \n",
    "                                # Create dictionary with submission data\n",
    "                                sub_dict = {\n",
    "                                    'subreddit': subreddit_name,\n",
    "                                    'id': submission.id,\n",
    "                                    'title': submission.title,\n",
    "                                    'author': str(submission.author),\n",
    "                                    'created_utc': dt.fromtimestamp(submission.created_utc),\n",
    "                                    'score': submission.score,\n",
    "                                    'upvote_ratio': submission.upvote_ratio,\n",
    "                                    'num_comments': submission.num_comments,\n",
    "                                    'url': submission.url,\n",
    "                                    'is_self': submission.is_self,\n",
    "                                    'selftext': submission.selftext if submission.is_self else None,\n",
    "                                    'sort_method': 'search',\n",
    "                                    'time_filter': f\"{days_ago-30}-{days_ago}_days_ago\"\n",
    "                                }\n",
    "                                \n",
    "                                # Add to our collection and track the ID\n",
    "                                sub_dict_tuple = tuple(sorted(sub_dict.items()))\n",
    "                                sub_samples.add(sub_dict_tuple)\n",
    "                                existing_ids[subreddit_name].add(submission.id)\n",
    "                                \n",
    "                                time.sleep(sleep_amount)\n",
    "                            \n",
    "                            print(f\"Found {len(sub_samples)} total samples after search\")\n",
    "                            time.sleep(1)\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error with search approach: {str(e)}\")\n",
    "                    \n",
    "                    # Convert back to list of dicts and add to all submissions\n",
    "                    additional_samples = [dict(items) for items in sub_samples]\n",
    "                    all_submissions.extend(additional_samples)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error collecting from r/{subreddit_name}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Return as dataframe and deduplicate by ID\n",
    "        result_df = pd.DataFrame(all_submissions)\n",
    "        if not result_df.empty:\n",
    "            result_df = result_df.drop_duplicates(subset=['id'])\n",
    "            \n",
    "            # Print final stats\n",
    "            for subreddit in subreddits:\n",
    "                sub_count = len(result_df[result_df['subreddit'] == subreddit])\n",
    "                print(f\"Final count for r/{subreddit}: {sub_count} posts\")\n",
    "                \n",
    "            return result_df\n",
    "        else:\n",
    "            return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import api_keys\n",
    "\n",
    "# You'll need to get these from your Reddit API application\n",
    "CLIENT_ID = api_keys.reddit_client_id\n",
    "CLIENT_SECRET = api_keys.reddit_secret\n",
    "USER_AGENT = f\"script:data_sampler:v1.0 (by /u/{api_keys.reddit_username})\"\n",
    "\n",
    "sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
    "\n",
    "# List of subreddits\n",
    "subreddits_subset = list(subreddits.values())[2:]\n",
    "sample_size = 6000\n",
    "\n",
    "# Load existing data if available\n",
    "try:\n",
    "    existing_df = pd.read_csv(\"existing_reddit_data.csv\")\n",
    "    print(f\"Loaded existing data with {len(existing_df)} rows\")\n",
    "except FileNotFoundError:\n",
    "    existing_df = None\n",
    "    print(\"No existing data found, starting fresh\")\n",
    "\n",
    "# Get samples with existing data to avoid duplicates\n",
    "samples_df = sampler.get_samples(\n",
    "    subreddits=subreddits_subset,\n",
    "    sample_size=sample_size,\n",
    "    submission_type=\"all\",\n",
    "    existing_data=df3.copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "GriefSupport           4800\n",
       "lonely                 4800\n",
       "Anxiety                4800\n",
       "addiction              4800\n",
       "sexualassault          4696\n",
       "AskLGBT                4214\n",
       "EatingDisorders        4013\n",
       "abusesurvivors         3159\n",
       "bullying               3066\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat dfs\n",
    "\n",
    "df4 = pd.concat([df3, samples_df_new], ignore_index=True)\n",
    "df4.drop_duplicates(subset=['id'], inplace=True)\n",
    "df4['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df4.copy()\n",
    "\n",
    "\n",
    "def clean_reddit(df):\n",
    "\n",
    "    # df['title'] = df['title'].str.replace('nan', '', regex=False)\n",
    "    \n",
    "    df.loc[df['selftext'] == 'None', 'selftext'] = ''\n",
    "    df.loc[df['selftext'] == 'nan', 'selftext'] = ''\n",
    "    \n",
    "    df['title_text'] = df['title'].astype(str)+\" \\n---\\n \"+df['selftext'].astype(str)\n",
    "    df['title_text'] = df['title_text'].str.replace(' \\n---\\n nan', '')\n",
    "    df['title_text'] = df['title_text'].str.replace(' \\n---\\n None', '')\n",
    "    df['title_text'] = df['title_text'].str.replace('None \\n---\\n ', '')\n",
    "    display(df[df['title_text'].str.contains(' \\n---\\n nan')][['title', 'selftext', 'title_text']])\n",
    "\n",
    "    # - Make sure title_text was combined correctly (it seems if body was NaN then the combination is NaN, which is incorrect)\n",
    "\n",
    "    display(df[df['title_text'].str.contains('nan ')][['title', 'selftext', 'title_text']])\n",
    "    display(df[df['title_text'].str.contains(' nan')][['title', 'selftext', 'title_text']])\n",
    "\n",
    "    # remove extremely short samples\n",
    "\n",
    "    from construct_tracker.utils import word_count\n",
    "\n",
    "    df['word_count'] = word_count.word_count(df['title_text'].to_list())\n",
    "\n",
    "    df = df[df['word_count']>=5]\n",
    "    df = df[df['title']!='[ Removed by Reddit ]']\n",
    "    df = df.drop_duplicates(subset=['title_text'])\n",
    "    return df\n",
    "\n",
    "df = clean_reddit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "lonely                 4795\n",
       "Anxiety                4792\n",
       "addiction              4728\n",
       "sexualassault          4692\n",
       "GriefSupport           4658\n",
       "AskLGBT                4204\n",
       "EatingDisorders        4007\n",
       "abusesurvivors         3127\n",
       "bullying               2994\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "import datetime\n",
    "\n",
    "current_timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "df.to_csv(f\"data/input/updated_reddit_data_{current_timestamp}.csv\", index=False)\n",
    "# print(f\"Saved {len(samples_df_new)} posts to updated_reddit_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to collect 1800 more posts for r/workplace_bullying\n",
      "Collected 1000 samples from r/workplace_bullying (top/all)\n",
      "Using before_id=1dmx96m to get older posts for top/year\n",
      "Skipping already seen post 1h7k5ou\n",
      "Collected 1000 samples from r/workplace_bullying (top/year)\n",
      "Using before_id=1ii9bov to get older posts for top/month\n",
      "Collected 1000 samples from r/workplace_bullying (top/month)\n",
      "Using before_id=1haean3 to get older posts for top/week\n",
      "Collected 1000 samples from r/workplace_bullying (top/week)\n",
      "Using before_id=1ggbh8u to get older posts for top/day\n",
      "Collected 1000 samples from r/workplace_bullying (top/day)\n",
      "Using before_id=1hdctsx to get older posts for controversial/all\n",
      "Skipping already seen post 1dgz7s8\n",
      "Collected 1067 samples from r/workplace_bullying (controversial/all)\n",
      "Using before_id=1iivr9s to get older posts for controversial/year\n",
      "Collected 1067 samples from r/workplace_bullying (controversial/year)\n",
      "Using before_id=1h86uj1 to get older posts for controversial/month\n",
      "Collected 1067 samples from r/workplace_bullying (controversial/month)\n",
      "Using before_id=1h4dtjs to get older posts for controversial/week\n",
      "Collected 1067 samples from r/workplace_bullying (controversial/week)\n",
      "Using before_id=1hym1kr to get older posts for controversial/day\n",
      "Collected 1067 samples from r/workplace_bullying (controversial/day)\n",
      "Skipping already seen post 1j8mwp4\n",
      "Skipping already seen post 1j74n2q\n",
      "Skipping already seen post 1j3xtds\n",
      "Skipping already seen post 1ibfr3o\n",
      "Skipping already seen post 1ibjzau\n",
      "Skipping already seen post 1ibar3l\n",
      "Skipping already seen post 1hjaspt\n",
      "Skipping already seen post 1hcmx6h\n",
      "Skipping already seen post 1gxajnd\n",
      "Skipping already seen post 1goinv2\n",
      "Collected 1430 samples from r/workplace_bullying (hot/all)\n",
      "Skipping already seen post 1j820sy\n",
      "Skipping already seen post 1j3xtds\n",
      "Skipping already seen post 1izzs99\n",
      "Skipping already seen post 1iaiqgq\n",
      "Skipping already seen post 1i8bld3\n",
      "Skipping already seen post 1i7efnv\n",
      "Skipping already seen post 1i5475n\n",
      "Skipping already seen post 1hyo22h\n",
      "Skipping already seen post 1hw9ogq\n",
      "Skipping already seen post 1hta0k6\n",
      "Skipping already seen post 1hsgr2a\n",
      "Skipping already seen post 1hmwmz0\n",
      "Skipping already seen post 1hjqg7o\n",
      "Skipping already seen post 1gwtvs2\n",
      "Skipping already seen post 1go5b44\n",
      "Skipping already seen post 1gl6yau\n",
      "Skipping already seen post 1g90ave\n",
      "Collected 1430 samples from r/workplace_bullying (hot/year)\n",
      "Skipping already seen post 1j5fxq3\n",
      "Skipping already seen post 1j47ohl\n",
      "Skipping already seen post 1iyyv5s\n",
      "Skipping already seen post 1izbvmu\n",
      "Skipping already seen post 1i2si1a\n",
      "Skipping already seen post 1he4f4m\n",
      "Skipping already seen post 1hdb74z\n",
      "Skipping already seen post 1gxzuvj\n",
      "Skipping already seen post 1gdidsd\n",
      "Collected 1430 samples from r/workplace_bullying (hot/month)\n",
      "Skipping already seen post 1itl6tt\n",
      "Skipping already seen post 1i1tbm8\n",
      "Skipping already seen post 1hp033s\n",
      "Skipping already seen post 1hf19gq\n",
      "Skipping already seen post 1hdzelt\n",
      "Skipping already seen post 1h1d31r\n",
      "Skipping already seen post 1gsyx4g\n",
      "Collected 1430 samples from r/workplace_bullying (hot/week)\n",
      "Skipping already seen post 1j436pz\n",
      "Skipping already seen post 1j0wkgb\n",
      "Skipping already seen post 1inp7lu\n",
      "Skipping already seen post 1i9gb7p\n",
      "Skipping already seen post 1i3h4vr\n",
      "Skipping already seen post 1hujdky\n",
      "Skipping already seen post 1gdv3wl\n",
      "Skipping already seen post 1g71ozp\n",
      "Collected 1430 samples from r/workplace_bullying (hot/day)\n",
      "Skipping already seen post 1ityaqr\n",
      "Skipping already seen post 1ifhf8t\n",
      "Skipping already seen post 1icozs9\n",
      "Skipping already seen post 1hox181\n",
      "Skipping already seen post 1hldvg7\n",
      "Skipping already seen post 1hcmx6h\n",
      "Skipping already seen post 1h5aws8\n",
      "Skipping already seen post 1gta940\n",
      "Skipping already seen post 1grc58d\n",
      "Collected 1430 samples from r/workplace_bullying (new/all)\n",
      "Skipping already seen post 1j6kh47\n",
      "Skipping already seen post 1ifskie\n",
      "Skipping already seen post 1ic5lx8\n",
      "Skipping already seen post 1hsiu0l\n",
      "Skipping already seen post 1hhnq8e\n",
      "Skipping already seen post 1hf8y97\n",
      "Skipping already seen post 1goeu71\n",
      "Skipping already seen post 1gbwcxc\n",
      "Collected 1430 samples from r/workplace_bullying (new/year)\n",
      "Skipping already seen post 1j7pt48\n",
      "Skipping already seen post 1j2b3la\n",
      "Skipping already seen post 1ih93ih\n",
      "Skipping already seen post 1i5ja3e\n",
      "Skipping already seen post 1hp4k4m\n",
      "Skipping already seen post 1ghd6vr\n",
      "Collected 1430 samples from r/workplace_bullying (new/month)\n",
      "Skipping already seen post 1j68s2l\n",
      "Skipping already seen post 1i6y7wn\n",
      "Skipping already seen post 1htjymi\n",
      "Skipping already seen post 1h4pxa0\n",
      "Skipping already seen post 1gixru4\n",
      "Skipping already seen post 1g9x0qq\n",
      "Collected 1430 samples from r/workplace_bullying (new/week)\n",
      "Skipping already seen post 1j8724c\n",
      "Skipping already seen post 1j7exk3\n",
      "Skipping already seen post 1ihv5tw\n",
      "Skipping already seen post 1ibact1\n",
      "Skipping already seen post 1i7ke70\n",
      "Skipping already seen post 1i4kw89\n",
      "Skipping already seen post 1hwfjcu\n",
      "Skipping already seen post 1hkljf1\n",
      "Skipping already seen post 1hcg1hh\n",
      "Skipping already seen post 1gp0u3l\n",
      "Skipping already seen post 1gk1fw8\n",
      "Skipping already seen post 1gfz9pc\n",
      "Collected 1430 samples from r/workplace_bullying (new/day)\n",
      "Need to collect 1800 more posts for r/domesticviolence\n",
      "Collected 998 samples from r/domesticviolence (top/all)\n",
      "Using before_id=170xb7p to get older posts for top/year\n",
      "Collected 998 samples from r/domesticviolence (top/year)\n",
      "Using before_id=xg7wf5 to get older posts for top/month\n",
      "Collected 998 samples from r/domesticviolence (top/month)\n",
      "Using before_id=1dri1dy to get older posts for top/week\n",
      "Collected 998 samples from r/domesticviolence (top/week)\n",
      "Using before_id=irf13f to get older posts for top/day\n",
      "Collected 998 samples from r/domesticviolence (top/day)\n",
      "Using before_id=1b9m3qk to get older posts for controversial/all\n",
      "Collected 998 samples from r/domesticviolence (controversial/all)\n",
      "Using before_id=stj89y to get older posts for controversial/year\n",
      "Collected 998 samples from r/domesticviolence (controversial/year)\n",
      "Using before_id=1ewtgab to get older posts for controversial/month\n",
      "Collected 998 samples from r/domesticviolence (controversial/month)\n",
      "Using before_id=f427fj to get older posts for controversial/week\n",
      "Collected 998 samples from r/domesticviolence (controversial/week)\n",
      "Using before_id=u9ib8o to get older posts for controversial/day\n",
      "Collected 998 samples from r/domesticviolence (controversial/day)\n",
      "Skipping already seen post 1ijk82i\n",
      "Collected 1800 samples from r/domesticviolence (hot/all)\n",
      "Final count for r/workplace_bullying: 1430 posts\n",
      "Final count for r/domesticviolence: 1800 posts\n"
     ]
    }
   ],
   "source": [
    "sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
    "\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"workplace_bullying\": \"bullying\",\n",
    "    \"domesticviolence\": \"abusesurvivors\"\n",
    "}\n",
    "\n",
    "sample_size = 1800\n",
    "\n",
    "# Load existing data if available\n",
    "\n",
    "# Get samples with existing data to avoid duplicates\n",
    "samples_df2 = sampler.get_samples(\n",
    "    subreddits=list(subreddits_to_merge.keys()),\n",
    "    sample_size=sample_size,\n",
    "    submission_type=\"all\",\n",
    "    existing_data=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to collect 800 more posts for r/asktransgender\n",
      "Collected 800 samples from r/asktransgender (top/all)\n",
      "Need to collect 800 more posts for r/EDAnonymous\n",
      "Collected 800 samples from r/EDAnonymous (top/all)\n",
      "Final count for r/asktransgender: 800 posts\n",
      "Final count for r/EDAnonymous: 800 posts\n"
     ]
    }
   ],
   "source": [
    "sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
    "\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"asktransgender\": \"AskLGBT\",\n",
    "    \"EDAnonymous\": \"EatingDisorders\",\n",
    "}\n",
    "\n",
    "sample_size = 800\n",
    "\n",
    "# Load existing data if available\n",
    "\n",
    "# Get samples with existing data to avoid duplicates\n",
    "samples_df3 = sampler.get_samples(\n",
    "    subreddits=list(subreddits_to_merge.keys()),\n",
    "    sample_size=sample_size,\n",
    "    submission_type=\"all\",\n",
    "    existing_data=None\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, selftext, title_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>I was SA'd by my nanny as a child</td>\n",
       "      <td>\\nNeed advice/Rant! \\n\\nI don't know why I'm p...</td>\n",
       "      <td>I was SA'd by my nanny as a child \\n---\\n \\nNe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "      <td>Hey everyone, I‘ve been nying for a family for...</td>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "      <td>So my a passed a few weeks ago and it was a to...</td>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "      <td>I’m so sad everyday since this has happened. I...</td>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2415   Circa summer 2016 I overheard a young nanny te...   \n",
       "3155                   I was SA'd by my nanny as a child   \n",
       "4606   I am a nanny and need advice on an abusive fam...   \n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "14277             my beautiful nana passed away tonight    \n",
       "14645  My nana passed and I don’t feel supported by t...   \n",
       "16171  My daughter was with our nanny and choked, and...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "2415                                                 NaN   \n",
       "3155   \\nNeed advice/Rant! \\n\\nI don't know why I'm p...   \n",
       "4606   Hey everyone, I‘ve been nying for a family for...   \n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "14277                                                NaN   \n",
       "14645  So my a passed a few weeks ago and it was a to...   \n",
       "16171  I’m so sad everyday since this has happened. I...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "2415   Circa summer 2016 I overheard a young nanny te...  \n",
       "3155   I was SA'd by my nanny as a child \\n---\\n \\nNe...  \n",
       "4606   I am a nanny and need advice on an abusive fam...  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "14277             my beautiful nana passed away tonight   \n",
       "14645  My nana passed and I don’t feel supported by t...  \n",
       "16171  My daughter was with our nanny and choked, and...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# concat DFs\n",
    "\n",
    "df5 = pd.concat([df, samples_df2, samples_df3], ignore_index=True)\n",
    "df5 = clean_reddit(df5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to collect 600 more posts for r/cyberbullying\n",
      "Collected 600 samples from r/cyberbullying (top/all)\n",
      "Final count for r/cyberbullying: 600 posts\n"
     ]
    }
   ],
   "source": [
    "sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
    "\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"cyberbullying\": \"bullying\",\n",
    "}\n",
    "\n",
    "sample_size = 600\n",
    "\n",
    "# Load existing data if available\n",
    "\n",
    "# Get samples with existing data to avoid duplicates\n",
    "samples_df3 = sampler.get_samples(\n",
    "    subreddits=list(subreddits_to_merge.keys()),\n",
    "    sample_size=sample_size,\n",
    "    submission_type=\"all\",\n",
    "    existing_data=None\n",
    ")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, selftext, title_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>I was SA'd by my nanny as a child</td>\n",
       "      <td>\\nNeed advice/Rant! \\n\\nI don't know why I'm p...</td>\n",
       "      <td>I was SA'd by my nanny as a child \\n---\\n \\nNe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "      <td>Hey everyone, I‘ve been nying for a family for...</td>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "      <td>So my a passed a few weeks ago and it was a to...</td>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "      <td>I’m so sad everyday since this has happened. I...</td>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2415   Circa summer 2016 I overheard a young nanny te...   \n",
       "3155                   I was SA'd by my nanny as a child   \n",
       "4606   I am a nanny and need advice on an abusive fam...   \n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "14277             my beautiful nana passed away tonight    \n",
       "14645  My nana passed and I don’t feel supported by t...   \n",
       "16171  My daughter was with our nanny and choked, and...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "2415                                                 NaN   \n",
       "3155   \\nNeed advice/Rant! \\n\\nI don't know why I'm p...   \n",
       "4606   Hey everyone, I‘ve been nying for a family for...   \n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "14277                                                NaN   \n",
       "14645  So my a passed a few weeks ago and it was a to...   \n",
       "16171  I’m so sad everyday since this has happened. I...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "2415   Circa summer 2016 I overheard a young nanny te...  \n",
       "3155   I was SA'd by my nanny as a child \\n---\\n \\nNe...  \n",
       "4606   I am a nanny and need advice on an abusive fam...  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "14277             my beautiful nana passed away tonight   \n",
       "14645  My nana passed and I don’t feel supported by t...  \n",
       "16171  My daughter was with our nanny and choked, and...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df6 = pd.concat([df5, samples_df3], ignore_index=True)\n",
    "df6 = clean_reddit(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "AskLGBT                5004\n",
       "bullying               4984\n",
       "abusesurvivors         4920\n",
       "EatingDisorders        4802\n",
       "lonely                 4795\n",
       "Anxiety                4792\n",
       "addiction              4728\n",
       "sexualassault          4692\n",
       "GriefSupport           4658\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace subreddit names using the dictionary, where values should be replaced by their keys\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"workplace_bullying\": \"bullying\",\n",
    "    \"domesticviolence\": \"abusesurvivors\",\n",
    "    'asktransgender': 'AskLGBT', \n",
    "    'EDAnonymous': 'EatingDisorders',\n",
    "    \"cyberbullying\": \"bullying\",\n",
    "}\n",
    "df6['subreddit'] = df6['subreddit'].replace(subreddits_to_merge)\n",
    "\n",
    "df6['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, selftext, title_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>I was SA'd by my nanny as a child</td>\n",
       "      <td>\\nNeed advice/Rant! \\n\\nI don't know why I'm p...</td>\n",
       "      <td>I was SA'd by my nanny as a child \\n---\\n \\nNe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "      <td>Hey everyone, I‘ve been nying for a family for...</td>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "      <td>So my a passed a few weeks ago and it was a to...</td>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "      <td>I’m so sad everyday since this has happened. I...</td>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58775</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2415   Circa summer 2016 I overheard a young nanny te...   \n",
       "3155                   I was SA'd by my nanny as a child   \n",
       "4606   I am a nanny and need advice on an abusive fam...   \n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "14277             my beautiful nana passed away tonight    \n",
       "14645  My nana passed and I don’t feel supported by t...   \n",
       "16171  My daughter was with our nanny and choked, and...   \n",
       "58775  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "2415                                                 NaN   \n",
       "3155   \\nNeed advice/Rant! \\n\\nI don't know why I'm p...   \n",
       "4606   Hey everyone, I‘ve been nying for a family for...   \n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "14277                                                NaN   \n",
       "14645  So my a passed a few weeks ago and it was a to...   \n",
       "16171  I’m so sad everyday since this has happened. I...   \n",
       "58775  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "2415   Circa summer 2016 I overheard a young nanny te...  \n",
       "3155   I was SA'd by my nanny as a child \\n---\\n \\nNe...  \n",
       "4606   I am a nanny and need advice on an abusive fam...  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "14277             my beautiful nana passed away tonight   \n",
       "14645  My nana passed and I don’t feel supported by t...  \n",
       "16171  My daughter was with our nanny and choked, and...  \n",
       "58775  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df6 = clean_reddit(df6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, selftext, title_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6[df6['title_text'].str.contains(' \\n---\\n None')][['title', 'selftext', 'title_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "AskLGBT                5004\n",
       "bullying               4936\n",
       "abusesurvivors         4907\n",
       "lonely                 4795\n",
       "EatingDisorders        4795\n",
       "Anxiety                4788\n",
       "addiction              4705\n",
       "sexualassault          4691\n",
       "GriefSupport           4564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to collect 300 more posts for r/grief\n",
      "Collected 300 samples from r/grief (top/all)\n",
      "Final count for r/grief: 300 posts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, selftext, title_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58686</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "58686  Mother’s Day approaching, me and my nan are mi...   \n",
       "\n",
       "                                                selftext  \\\n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "58686  So it’s my first Mother’s Day without my mum, ...   \n",
       "\n",
       "                                              title_text  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "58686  Mother’s Day approaching, me and my nan are mi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Circa summer 2016 I overheard a young nanny te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>I was SA'd by my nanny as a child</td>\n",
       "      <td>\\nNeed advice/Rant! \\n\\nI don't know why I'm p...</td>\n",
       "      <td>I was SA'd by my nanny as a child \\n---\\n \\nNe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "      <td>Hey everyone, I‘ve been nying for a family for...</td>\n",
       "      <td>I am a nanny and need advice on an abusive fam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14086</th>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "      <td>the title is as is, I (F20) feel stupid becaus...</td>\n",
       "      <td>I lost my mum and the. My nan 20 days later an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14277</th>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my beautiful nana passed away tonight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14645</th>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "      <td>So my a passed a few weeks ago and it was a to...</td>\n",
       "      <td>My nana passed and I don’t feel supported by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16171</th>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "      <td>I’m so sad everyday since this has happened. I...</td>\n",
       "      <td>My daughter was with our nanny and choked, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58686</th>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "      <td>So it’s my first Mother’s Day without my mum, ...</td>\n",
       "      <td>Mother’s Day approaching, me and my nan are mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66617</th>\n",
       "      <td>my bird died last night and i didn’t get to sa...</td>\n",
       "      <td>None</td>\n",
       "      <td>my bird died last night and i didn’t get to sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2415   Circa summer 2016 I overheard a young nanny te...   \n",
       "3155                   I was SA'd by my nanny as a child   \n",
       "4606   I am a nanny and need advice on an abusive fam...   \n",
       "14086  I lost my mum and the. My nan 20 days later an...   \n",
       "14277             my beautiful nana passed away tonight    \n",
       "14645  My nana passed and I don’t feel supported by t...   \n",
       "16171  My daughter was with our nanny and choked, and...   \n",
       "58686  Mother’s Day approaching, me and my nan are mi...   \n",
       "66617  my bird died last night and i didn’t get to sa...   \n",
       "\n",
       "                                                selftext  \\\n",
       "2415                                                 NaN   \n",
       "3155   \\nNeed advice/Rant! \\n\\nI don't know why I'm p...   \n",
       "4606   Hey everyone, I‘ve been nying for a family for...   \n",
       "14086  the title is as is, I (F20) feel stupid becaus...   \n",
       "14277                                                NaN   \n",
       "14645  So my a passed a few weeks ago and it was a to...   \n",
       "16171  I’m so sad everyday since this has happened. I...   \n",
       "58686  So it’s my first Mother’s Day without my mum, ...   \n",
       "66617                                               None   \n",
       "\n",
       "                                              title_text  \n",
       "2415   Circa summer 2016 I overheard a young nanny te...  \n",
       "3155   I was SA'd by my nanny as a child \\n---\\n \\nNe...  \n",
       "4606   I am a nanny and need advice on an abusive fam...  \n",
       "14086  I lost my mum and the. My nan 20 days later an...  \n",
       "14277             my beautiful nana passed away tonight   \n",
       "14645  My nana passed and I don’t feel supported by t...  \n",
       "16171  My daughter was with our nanny and choked, and...  \n",
       "58686  Mother’s Day approaching, me and my nan are mi...  \n",
       "66617  my bird died last night and i didn’t get to sa...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "AskLGBT                5004\n",
       "bullying               4936\n",
       "abusesurvivors         4907\n",
       "lonely                 4795\n",
       "EatingDisorders        4795\n",
       "Anxiety                4788\n",
       "addiction              4705\n",
       "sexualassault          4691\n",
       "GriefSupport           4564\n",
       "grief                   277\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = RedditSampler(CLIENT_ID, CLIENT_SECRET, USER_AGENT)\n",
    "\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"grief\": \"bullying\",\n",
    "}\n",
    "\n",
    "sample_size = 300\n",
    "\n",
    "# Load existing data if available\n",
    "\n",
    "# Get samples with existing data to avoid duplicates\n",
    "samples_df4 = sampler.get_samples(\n",
    "    subreddits=list(subreddits_to_merge.keys()),\n",
    "    sample_size=sample_size,\n",
    "    submission_type=\"all\",\n",
    "    existing_data=None\n",
    ")\n",
    "    \n",
    "df6 = pd.concat([df6, samples_df4], ignore_index=True)\n",
    "df6 = clean_reddit(df6)\n",
    "\n",
    "# replace subreddit names using the dictionary, where values should be replaced by their keys\n",
    "# List of subreddits\n",
    "subreddits_to_merge = {\n",
    "    \"workplace_bullying\": \"bullying\",\n",
    "    \"domesticviolence\": \"abusesurvivors\",\n",
    "    'asktransgender': 'AskLGBT', \n",
    "    'EDAnonymous': 'EatingDisorders',\n",
    "    \"cyberbullying\": \"bullying\",\n",
    "}\n",
    "df6['subreddit'] = df6['subreddit'].replace(subreddits_to_merge)\n",
    "\n",
    "df6['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['subtype'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "AskLGBT                5004\n",
       "bullying               4936\n",
       "abusesurvivors         4907\n",
       "GriefSupport           4841\n",
       "lonely                 4795\n",
       "EatingDisorders        4795\n",
       "Anxiety                4788\n",
       "addiction              4705\n",
       "sexualassault          4691\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_to_merge = {\n",
    "    \"workplace_bullying\": \"bullying\",\n",
    "    \"domesticviolence\": \"abusesurvivors\",\n",
    "    'asktransgender': 'AskLGBT', \n",
    "    'EDAnonymous': 'EatingDisorders',\n",
    "    \"cyberbullying\": \"bullying\",\n",
    "    \"grief\": \"GriefSupport\"\n",
    "}\n",
    "df6['subreddit'] = df6['subreddit'].replace(subreddits_to_merge)\n",
    "\n",
    "df6['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# current_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "df6.to_csv(f'data/input/reddit_13_mental_health_4691-6164-posts_{current_timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove some duplicate documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6164\n",
       "relationship_advice    6059\n",
       "depression             5881\n",
       "selfharm               5110\n",
       "AskLGBT                5004\n",
       "bullying               4936\n",
       "abusesurvivors         4907\n",
       "GriefSupport           4841\n",
       "lonely                 4795\n",
       "EatingDisorders        4795\n",
       "Anxiety                4788\n",
       "addiction              4705\n",
       "sexualassault          4691\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "current_timestamp = '20250311_123431'\n",
    "results_df = pd.read_csv(f'data/input/reddit_13_mental_health_4691-6164-posts_{current_timestamp}.csv')\n",
    "results_df['subreddit'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           6130\n",
       "relationship_advice    6057\n",
       "depression             5862\n",
       "selfharm               5105\n",
       "AskLGBT                4998\n",
       "bullying               4923\n",
       "abusesurvivors         4902\n",
       "GriefSupport           4830\n",
       "EatingDisorders        4789\n",
       "lonely                 4787\n",
       "Anxiety                4785\n",
       "addiction              4701\n",
       "sexualassault          4677\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.drop_duplicates(subset=['title_text'], inplace=True)\n",
    "results_df = results_df[results_df['title']!='[ Removed by Reddit ]']\n",
    "results_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(f'data/input/reddit_13_mental_health_4677-6130-posts_{current_timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sample of 4600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           4600\n",
       "relationship_advice    4600\n",
       "depression             4600\n",
       "selfharm               4600\n",
       "AskLGBT                4600\n",
       "bullying               4600\n",
       "abusesurvivors         4600\n",
       "GriefSupport           4600\n",
       "EatingDisorders        4600\n",
       "lonely                 4600\n",
       "Anxiety                4600\n",
       "addiction              4600\n",
       "sexualassault          4600\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subsample to 2800 samples per subreddit\n",
    "\n",
    "df = results_df.copy()\n",
    "\n",
    "n = 4600\n",
    "\n",
    "# Create an empty dataframe to store the result\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Get value counts of subreddits\n",
    "subreddit_counts = df['subreddit'].value_counts()\n",
    "\n",
    "# For each subreddit\n",
    "for subreddit, count in subreddit_counts.items():\n",
    "    # Get all rows for this subreddit\n",
    "    temp_df = df[df['subreddit'] == subreddit]\n",
    "    \n",
    "    # If count exceeds 6000, randomly sample 6000 rows\n",
    "    if count > n:\n",
    "        temp_df = temp_df.sample(n, random_state=42)\n",
    "    \n",
    "    # Add to the result dataframe\n",
    "    result_df = pd.concat([result_df, temp_df])\n",
    "\n",
    "# Reset index for the final result\n",
    "result_df = result_df.reset_index(drop=True)\n",
    "result_df['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'data/input/reddit_13_mental_health_4600-posts_{current_timestamp}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>url</th>\n",
       "      <th>is_self</th>\n",
       "      <th>selftext</th>\n",
       "      <th>sort_method</th>\n",
       "      <th>time_filter</th>\n",
       "      <th>title_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1itjza2</td>\n",
       "      <td>I’m going to college</td>\n",
       "      <td>wackybastard</td>\n",
       "      <td>2025-02-19 18:27:11</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>True</td>\n",
       "      <td>I am attending college in the fall. I’m consta...</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’m going to college \\n---\\n I am attending co...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1e65p1n</td>\n",
       "      <td>I ruined my own life at 18</td>\n",
       "      <td>Broad-Technician-536</td>\n",
       "      <td>2024-07-18 03:40:46</td>\n",
       "      <td>267</td>\n",
       "      <td>0.96</td>\n",
       "      <td>42</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>True</td>\n",
       "      <td>I don’t expect sympathy( I actually expect cri...</td>\n",
       "      <td>top</td>\n",
       "      <td>year</td>\n",
       "      <td>I ruined my own life at 18 \\n---\\n I don’t exp...</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1is02j9</td>\n",
       "      <td>I'm too broken.</td>\n",
       "      <td>Personal_Library_121</td>\n",
       "      <td>2025-02-17 19:51:47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>True</td>\n",
       "      <td>My brain is broken and always will be. Even wi...</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm too broken. \\n---\\n My brain is broken and...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1ipvc6o</td>\n",
       "      <td>My boyfriend cheated on me</td>\n",
       "      <td>Nervous-Reindeer-327</td>\n",
       "      <td>2025-02-15 01:19:49</td>\n",
       "      <td>11</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>True</td>\n",
       "      <td>5 years. No family or friends \\nQuick and pain...</td>\n",
       "      <td>top</td>\n",
       "      <td>month</td>\n",
       "      <td>My boyfriend cheated on me \\n---\\n 5 years. No...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>1it7dem</td>\n",
       "      <td>I hate that I’m back here. I thought I was bet...</td>\n",
       "      <td>WeeklyFurball</td>\n",
       "      <td>2025-02-19 09:56:50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/SuicideWatch/comments...</td>\n",
       "      <td>True</td>\n",
       "      <td>It has been about 3 years since I managed to g...</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I hate that I’m back here. I thought I was bet...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59795</th>\n",
       "      <td>sexualassault</td>\n",
       "      <td>1iwt3gu</td>\n",
       "      <td>Scared to leave the house</td>\n",
       "      <td>Silver_Half8669</td>\n",
       "      <td>2025-02-23 22:57:07</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reddit.com/r/sexualassault/comment...</td>\n",
       "      <td>True</td>\n",
       "      <td>Ever since my ex and I broke up four months ag...</td>\n",
       "      <td>top</td>\n",
       "      <td>month</td>\n",
       "      <td>Scared to leave the house \\n---\\n Ever since m...</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59796</th>\n",
       "      <td>sexualassault</td>\n",
       "      <td>1cevj8i</td>\n",
       "      <td>Help! My son’s 15 year old male friend is bein...</td>\n",
       "      <td>Critical_Valuable_92</td>\n",
       "      <td>2024-04-27 22:19:43</td>\n",
       "      <td>18</td>\n",
       "      <td>0.96</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.reddit.com/r/sexualassault/comment...</td>\n",
       "      <td>True</td>\n",
       "      <td>Things my sons have claimed this kid has done:...</td>\n",
       "      <td>top</td>\n",
       "      <td>year</td>\n",
       "      <td>Help! My son’s 15 year old male friend is bein...</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59797</th>\n",
       "      <td>sexualassault</td>\n",
       "      <td>1afl6ii</td>\n",
       "      <td>My uncle touched me</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-31 11:01:45</td>\n",
       "      <td>47</td>\n",
       "      <td>0.96</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.reddit.com/r/sexualassault/comment...</td>\n",
       "      <td>True</td>\n",
       "      <td>On Sunday there was a family gathering. A part...</td>\n",
       "      <td>top</td>\n",
       "      <td>all</td>\n",
       "      <td>My uncle touched me \\n---\\n On Sunday there wa...</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59798</th>\n",
       "      <td>sexualassault</td>\n",
       "      <td>1bz0m6y</td>\n",
       "      <td>Noticed something at the library</td>\n",
       "      <td>FunPrimary2252</td>\n",
       "      <td>2024-04-08 11:22:31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.reddit.com/r/sexualassault/comment...</td>\n",
       "      <td>True</td>\n",
       "      <td>Me and another guy can't even fucking use the ...</td>\n",
       "      <td>controversial</td>\n",
       "      <td>all</td>\n",
       "      <td>Noticed something at the library  \\n---\\n Me a...</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59799</th>\n",
       "      <td>sexualassault</td>\n",
       "      <td>1dnxrq8</td>\n",
       "      <td>I feel bad for blocking him and I don't know w...</td>\n",
       "      <td>Positive-Dog-6881</td>\n",
       "      <td>2024-06-25 00:46:49</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.reddit.com/r/sexualassault/comment...</td>\n",
       "      <td>True</td>\n",
       "      <td>For context, I was SA'd by one of my friends w...</td>\n",
       "      <td>controversial</td>\n",
       "      <td>year</td>\n",
       "      <td>I feel bad for blocking him and I don't know w...</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59800 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit  ... word_count\n",
       "0       SuicideWatch  ...        126\n",
       "1       SuicideWatch  ...        190\n",
       "2       SuicideWatch  ...         84\n",
       "3       SuicideWatch  ...         13\n",
       "4       SuicideWatch  ...        136\n",
       "...              ...  ...        ...\n",
       "59795  sexualassault  ...        230\n",
       "59796  sexualassault  ...        298\n",
       "59797  sexualassault  ...        113\n",
       "59798  sexualassault  ...         78\n",
       "59799  sexualassault  ...        175\n",
       "\n",
       "[59800 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'reddit_13_mental_health_4600-posts_20250311_123431'\n",
    "df = pd.read_csv(f'./data/input/{filename}.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit_13_mental_health_4600-posts_20250311_123431'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           4000\n",
       "relationship_advice    4000\n",
       "depression             4000\n",
       "selfharm               4000\n",
       "AskLGBT                4000\n",
       "bullying               4000\n",
       "abusesurvivors         4000\n",
       "GriefSupport           4000\n",
       "EatingDisorders        4000\n",
       "lonely                 4000\n",
       "Anxiety                4000\n",
       "addiction              4000\n",
       "sexualassault          4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "SuicideWatch           600\n",
       "relationship_advice    600\n",
       "depression             600\n",
       "selfharm               600\n",
       "AskLGBT                600\n",
       "bullying               600\n",
       "abusesurvivors         600\n",
       "GriefSupport           600\n",
       "EatingDisorders        600\n",
       "lonely                 600\n",
       "Anxiety                600\n",
       "addiction              600\n",
       "sexualassault          600\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# For every subreddit, split into train (4000 posts) and test sets (600 posts)\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "for subreddit in df['subreddit'].unique():\n",
    "    subreddit_df = df[df['subreddit'] == subreddit]\n",
    "    # Shuffle rows\n",
    "    subreddit_df = subreddit_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Use concat instead of deprecated append\n",
    "    train_df = pd.concat([train_df, subreddit_df[:4000]], ignore_index=True)\n",
    "    test_df = pd.concat([test_df, subreddit_df[4000:4600]], ignore_index=True)\n",
    "\n",
    "# No need to reset_index again as ignore_index=True in concat already handles this\n",
    "train_df.to_csv(f'./data/input/{filename}_train.csv', index=False)\n",
    "test_df.to_csv(f'./data/input/{filename}_test.csv', index=False)\n",
    "train_df_ids = train_df['id'].values\n",
    "test_df_ids = test_df['id'].values\n",
    "\n",
    "# Save as variable in a py script\n",
    "with open(f'./data/input/{filename.replace(\"-\", \"_\")}_train_test_ids.py', 'w') as f:\n",
    "    f.write(f'train_ids = {train_df_ids.tolist()}')\n",
    "    f.write('\\n')\n",
    "    f.write(f'test_ids = {test_df_ids.tolist()}')\n",
    "\n",
    "df[df['id'].isin(test_df_ids)]['subreddit'].value_counts()\n",
    "display(train_df['subreddit'].value_counts())\n",
    "display(test_df['subreddit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything feels like a chore.  \n",
      "---\n",
      " Everything feels like a chore. I spent more than 20 minutes in bathroom for just brushing my teeth and washing my fucking face. \n",
      "\n",
      "I knew that all I had to do was just putting some stupid fucking toothpaste on the toothbrush but that alone took more than five minutes to do. I just stared at it, trying to process what I had to do step by step. \n",
      "\n",
      "And it happens every fucking morning. I can’t even find the energy to brush my fucking teeth how pathetic can one get more?  \n",
      "\n",
      "I decided to tell people \"I am not okay\" when close friends ask me \"how are you? Here is how it went... \n",
      "---\n",
      " Every single one of them left me on read. \n",
      "\n",
      "I am really not doing well isolated in quarantine and I get text conversations are the lowest form of communication. but it's all we got in these times. (I am in Michigan with the highest current covid cases in the US, and seeing people isn't really an option).\n",
      "\n",
      "I even texted my friend (who I was just Bestman for in October) that I am not doing well and really need to talk to someone and he has ghosted me. Many of these friends come to me when they are alone, depressed, or need advice. (Also he is the most glued to his phone type of person I have ever met). \n",
      "\n",
      "I am in therapy, and I get like regular people aren't qualified to discuss these topics sometimes and feel uncomfortable about the topic, but I guess I had hoped one of my friends would listen. I am feeling extra bad that I have to literally pay someone to listen to me, makes me wonder if I am insufferable. \n",
      "\n",
      "how do you not panic during recovery? \n",
      "---\n",
      " I (20ftm) have been struggling for as long as I can remember with an ed. When I was 15, it spiralled into all out bulimia. I've never found a facility that helped me, and I've been to several.\n",
      "\n",
      "Anyway, I've lost a ton of weight, and I hate how that looks. I would much prefer to look like I am a healthy weight, but the number! Every time the scale says I've gone up any amount I panic, and the cycle continues. I do a lot of gymnastics too, and I have panicked during recovery because the regained weight was affecting my routine.\n",
      "\n",
      "Help? \n",
      "\n",
      "Eating recovery; how did you do it? \n",
      "---\n",
      " For anyone who has recovered from starving themselves, how did you stop? How did it get better for you? Just wondering. \n",
      "\n",
      "What can we do as parents? \n",
      "---\n",
      " My boyfriend and I moved together 3 months ago after dating for around 6 years. He has a 12 year old daughter. His ex wife is obsessed with her body, weight and fitness (is/was bulimic) and has harassed the poor child about her weight her entire life. We have noticed the girl's growing preocupation with weight, body, food and calories and since moving in together I've found vomit in the toilet a couple of times, food wrappers tucked in her bedroom and suspicious trips to the bathroom after eating as well as mystery midnight \"showers\". My boyfriend is frozen, he says he doesn't know what to do and has been hiding his head in the sand not even wanting to discuss the topic with me. As a step parent, I don't know what to do. I want to help the poor girl before it gets really bad. Any advice? \n",
      "\n",
      "Girlfriends (F28) drinking makes me uncomfortable but I’m (M27) not sure why \n",
      "---\n",
      " Been with my girlfriend for about 1.5 years. Alcohol has always been in our relationship (I work in wine and she loves it) and I do drink. However drinking has become a difficult topic for us recently as her habits do make me uncomfortable. \n",
      "She admits that before we met she had a problem, eg 2+ bottles of wine per night. For me, I will have max 2 glasses per night as I don’t enjoy feeling drunk. \n",
      "Since I guess being in a better place and also after we have spoken about how her drinking makes me feel, she will have around 2-4 glasses of wine on normal nights  (which she sees as a big improvement that she is happy with) and 1-2 bottles on weekend nights. I have to say that she doesn’t do anything aggressive or leave the house or anything. Will just stay up late listening to music etc. \n",
      "All of this leads to ongoing arguments and tension as I will ask how much she plans on having that evening for example and then she gets frustrated and asks why she can’t just do her own thing, she’s an adult, just leave me alone etc. \n",
      "I guess my question is, do I just try to accept how much she wants to drink and get over it/ hang out in another room when she is drinking more heavily, or do I try to say no you have a problem and we need to sort it out (ie stop drinking at all?).  \n",
      "\n",
      "Killing myself \n",
      "---\n",
      " Dunno when, i just know I will soon. I’ve had an unsuccessful attempt 2 years ago and ended up in the ICU for 2months and the psych ward for 1 month, but now I know deep down this is the actual end. \n",
      "\n",
      "Shits been fucked the past years after my ICU and ward situation. It didn’t get better, trust me i tried. I just wanna get this off my chest and tell someone, even if its a bunch strangers who don’t know me.  \n",
      "\n",
      "Anyone wanna be in Squid Game? \n",
      "---\n",
      " I feel like this subreddit's community is the perfect place to recruit all the players for Squid Game. \n",
      "\n",
      "My son died due to my negligence  \n",
      "---\n",
      " I(26F) lost my son(3) due to me being a negligent mom. Even before he passed away my boy would always complain that I was not loving and cuddling with him as I loved his baby sister(9 months) more. \n",
      "\n",
      "I do agree I was at fault but dealing with a baby is complicated. My son tripped from the staircase of our apartment and got his head struck with the railing. Though he was rushed to hospital but was declared dead. My (38M) husband blames me for being a neglectful mother and says that I am incapable of taking care of our baby girl. \n",
      "\n",
      "I can no longer think straight and I think my husband is right. \n",
      "\n",
      "Would dying my hair make me more comfortable with being.. well, whatever I am? \n",
      "---\n",
      " I'm a male, but I feel far more comfortable with feminine names or pronouns used on me. I like she/her, but they/them also works. I can't grow my hair out because I feel really weird with hair longer than my chin-ish. I was thinking dying my hair would make me at least a little more feminine? I was planning on dying at the least the tips blue. Would it maybe make me more comfortable with myself? Make me not be dysphoric, or whatever I've been feeling, about myself? \n",
      "\n",
      "Job Searching \n",
      "---\n",
      " I've been on about 4 failed job interviews and recently about 5 minutes ago I felt like I just bombed another one. The guy gave me interview advice in the middle of the interview, and I felt like it went shitty. At the end it was ok but I don't know. Every time I fail an interview I just get really depressed and sad and it sucks cause I've had a good week with my Girlfriend and all, no fighting. I'm just tired of rejection. \n",
      "\n",
      "The thing about an anxiety disorder is that \n",
      "---\n",
      " You know it's stupid. \n",
      "\n",
      "You know with all your heart that it wasn't a big deal and that it should roll off of you.\n",
      "\n",
      "&#x200B;\n",
      "\n",
      "But that is where the disorder kicks in. \n",
      "\n",
      "Suddenly the small things is very big and it keeps growing in your head, and trying to escape from under skin.\n",
      "\n",
      "You know with all of your heart that you're being ridiculous and You hate every minute of it. \n",
      "\n",
      "my girlfriend is suicidal \n",
      "---\n",
      " 3 nights ago my girlfriend told me that she is suicidal. I asked her is there any reason and she told me that there isn’t and she just wants to die. I tried to be helpful and told her to think about the good things in life. She replied with “like what” and I said our relationship and she said sure but in a way she didn’t seem to care. She asked me that if there’s anything on my mind and I told her that i’m worried that I’m going to be a single dad but she said that at this rate you won’t even be a dad. I begged her to get professional help and she said that that she doesn’t want to. I don’t know what to do. After a couple hours she told me how she loves me and how grateful she is for me.  \n",
      "\n",
      "I can't tell if what I'm feeling is anxiety. \n",
      "---\n",
      " I have bad insomnia and no ability to nap. This causes symptoms like insomnia head aches and feeling exhausted. However despite this I struggle just to rest and do nothing when exhausted. I feel compelled to go on my phone and OCD about news, insomnia Reddit, or self help research. Is this anxiety? Why can't I just lay there silently and listen to music or something.  \n",
      "\n",
      "Anxiety for class presentations \n",
      "---\n",
      " Hello,\n",
      "\n",
      "I have always had terrible anxiety during class presentations, like I can’t even finish and need to excuse myself sometimes because I choke up and my heart starts racing. It’s honestly to the point where I don’t know what to do, I’m in college now. Luckily when it’s a group presentation I can just pass my part on to somebody else but it’s always awkward and embarrassing. Does anybody have any advice for this? \n",
      "\n",
      "Anxiety doesn’t really affect any other aspects of my life, only speaking in front of a crowd. I do fine talking to anybody one on one (for the most part) but anything beyond that it gets difficult. I just want to be able to name it through a presentation without having a freak out and feeling like an idiot for the rest of the day. \n",
      "\n",
      "I 32F am scared I’m going to lose my 34M boyfriend of 2 years? \n",
      "---\n",
      " Recently I’ve been having mental health issues, a mixture of anxiety and depression. Because of that recently I have been rather negative, I don’t mean to be I just feel like I’m the only boxer in the ring right now, I’m exhausted. Everything hits a little harder right now and I’m trying my best to manage it. Because of this my boyfriend feels understandably drained, but today he said he feels we might be better off apart because of it. I’m terrified, I feel like I’ve sabotaged my relationship. It hurts knowing he’s unhappy, I don’t know what to do. Do I let him go?  \n",
      "\n",
      "6 months later, I say goodnight to my girlfriend each night who passed away. Is this healthy?  \n",
      "---\n",
      " So long story short I was devastated when my girlfriend passed away suddenly and unexpectedly 6 months ago.. about a month later I was sort of back to “normal” for the most part\n",
      "\n",
      "I still think about her everyday and miss her each day but it does not consume me or cause dramatic side effects like depression or anything..\n",
      "\n",
      "One thing I’ve done each night at bedtime is say a prayer for her soul, her family and when the prayer ends I start talking to her out loud from my bed for 5 minutes or so.. just telling her I Love her, miss her, thank her for being the best, and updating her about my day or her family…\n",
      "\n",
      "Is this crazy and fucked? Or healthy grieving? Is it okay to keep doing this or should I try to stop? I like doing this  \n",
      "\n",
      "Someday I would like to be treated like I'm half as important as the rest of the humans \n",
      "---\n",
      " I'm a 43 y/o man who has been stuck in a small community where I will never fit in, all my life. I was bullied growing up and continue to feel bullied nearly every day of my life. Even worse, I have had children who are suffering the same fate.\n",
      "\n",
      "I am perfectly capable of defending myself both physically and mentally, so no one understands why I just don't. But it only makes things worse. The \"locals\" stick together no matter what and will gang up on me, no questions asked. Despite the fact that I have lived here for 34 years, I will clearly never be a local.\n",
      "\n",
      "I don't know if I can do this anymore. \n",
      "\n",
      "Thanks for reading my barely coherent rant \n",
      "\n",
      "I feel so anxious rn \n",
      "---\n",
      " Have to go to a class, and have to leave soon. One of my anxiety symptoms has come back and it's the \"it feels like I'm not taking enough breath in\" and I have to manually take deep breaths, but sometimes I stop and start breathing shallowly.\n",
      "\n",
      "I'm scared of having a panic attack in my class and me not able to manage it :(\n",
      "\n",
      "It's definitely happened before in different classes, I just AHHH i'm so done with fearing of 'having a panic attack in public' I want to get back to normal student life not me constantly being anxious of what ifs\n",
      "\n",
      "Honestly just need support right now 😭\n",
      "\n",
      "Edit: hi guys! This is kinda like a progress update and for anyone going through something similar. I still felt panicky as I arrived to school, but I was actually able to stay for my full class and study after while feeling pretty calm. Unfortunately I feel like I'm out of breath again? But I'm literally doing nothing, but anyways, it did get better!\n",
      "\n",
      "Having a panic attack feels scary to me especially when I'm not home, but I have the tools to manage one and it's scary to do things that are inherently scary but I'm proud of myself for doing so! I don't really know what to do now other than try to take deep breaths and slowly, but I know this moment too, shall pass.  \n",
      "\n",
      "Husband went to casino for my birthday, without me. \n",
      "---\n",
      " So yesterday was my birthday, had to work a 12 hour shift through the whole day. My coworkers and job are amazing and I had a great day. \n",
      "\n",
      "My husband had some leftovers heated up for me when I got home which was super nice of him. \n",
      "\n",
      "So I end up falling asleep late, and wake up and call him to see where he's at. \n",
      "\n",
      "He's at the casino with his buddy... Idk if I'm overreacting, or if I should just end it all now. \n",
      "\n",
      "We are both 29 been together almost 10 years, and have two sons together. \n",
      "\n",
      "About a year and a half now he has had issues with drugs and talking inappropriately with other women. \n",
      "\n",
      "I have begged him not to leave in the middle of the night, it makes me worry tremendously if he's cheating or overdosed somewhere. \n",
      "\n",
      "He just leaves, no note, nothing. Idk I don't even want to talk to him. How do I comprehend this situation? I feel like if he wants to act single, go ahead. I work my ass off, he has no job and he's the one who gets to go have fun? I'm really exhausted from it all and would appreciate any advice.\n",
      "\n",
      "Edit:\n",
      "I had no idea I would so many responses. I feel as though I should clarify a few things. Most of you are right, it's not about my birthday, it's not about him having fun without me. It was the point of disrespecting me when I ask him not to do something that is so standard in relationships.\n",
      "\n",
      "For a good 8 years we had an amazing relationship, we were best friends, he was my home. He held the same job that whole time, provided for his family. He is all I know, I thought I would grow old with him and never wanted another. \n",
      "\n",
      "He has made so many mistakes, he has broken me, he is lost. But I started seeing who he used to be again and I held on despite not being really happy.\n",
      "\n",
      "He has been getting better with his drug addiction, I told him I would not give up on him and for my kids I will make sure they have their dad for a long time. \n",
      "\n",
      "He does not gamble, that just happened to be what he was doing last night. \n",
      "\n",
      "I know I'm a fool, most days I want to run... Idk why I can't. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(n, '\\n') for n in test_df.sample(n=20)['title_text'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_psychometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
