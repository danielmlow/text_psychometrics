{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "\n",
    "\n",
    "def generate_timestamp(format = '%y-%m-%dT%H-%M-%S'):\n",
    "\tts = datetime.datetime.utcnow().strftime(format) # so you don't overwrite, and save timestamp\n",
    "\treturn ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dir = './../../../data/ctl/'\n",
    "output_dir = './data/input/ctl/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "set_names = ['train10_train_30perc' ,'train10_val_15perc','train10_test_15perc']\n",
    "\n",
    "dataset_dir = '/Users/danielmlow/data/ctl/input/datasets/'\n",
    "\n",
    "sub_dir = 'train10_subset_30'\n",
    "\n",
    "# Text \n",
    "train = pd.read_parquet(dataset_dir + f'{sub_dir}/{set_names[0]}_messages_texter.gzip', engine='pyarrow')\n",
    "val = pd.read_parquet(dataset_dir + f'{sub_dir}/{set_names[1]}_messages_texter.gzip', engine='pyarrow')\n",
    "test = pd.read_parquet(dataset_dir + f'{sub_dir}/{set_names[2]}_messages_texter.gzip', engine='pyarrow')\n",
    "\n",
    "# Metadata (i.e., target variables)\n",
    "train_metadata = pd.read_csv(dataset_dir + f'{sub_dir}/{set_names[0]}_metadata.csv', index_col = 0)\n",
    "val_metadata = pd.read_csv(dataset_dir+ f'{sub_dir}/{set_names[1]}_metadata.csv', index_col = 0)\n",
    "test_metadata = pd.read_csv(dataset_dir + f'{sub_dir}/{set_names[2]}_metadata.csv', index_col = 0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat messages\n",
    "\n",
    "# merge with metadata\n",
    "from tqdm import tqdm\n",
    "dfs = {}\n",
    "\n",
    "\n",
    "for split, messages_dv, metadata_df_i in zip(['train', 'val', 'test'], [train, val, test], [train_metadata, val_metadata, test_metadata]):\n",
    "\tmessages_concat = []\n",
    "\n",
    "\tfor i in  tqdm(metadata_df_i['conversation_id'].unique()):\n",
    "\t\tmessages_i = []\n",
    "\t\tmessages_dv_i = messages_dv[messages_dv['conversation_id']==i]\n",
    "\t\tif len(messages_dv_i) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tmessages_dv_i = messages_dv_i.sort_values('message_timestamp_utc')\n",
    "\t\tmessages_convo_i = [n.strip(' ') if n.endswith(('.', ',', ']', ')', '!','?', '>')) else n.strip(' ')+'.' for n in messages_dv_i['message'].tolist() ]\n",
    "\t\tX_i = ' '.join(messages_convo_i) # messages of 1 convo\n",
    "\t\tmessages_i.append(i)\n",
    "\t\tmessages_i.append(messages_dv_i['actor_id'].values[-1])\n",
    "\t\tmessages_i.append(str(messages_dv_i['message_timestamp_utc'].values[-1]).replace('.000000', ''))\n",
    "\t\tmessages_i.append(X_i)\n",
    "\t\tmessages_concat.append(messages_i)\n",
    "\n",
    "\tmessages_concat_df = pd.DataFrame(messages_concat, columns = ['conversation_id', 'actor_id', 'conversation_end_time_utc', 'message'])\n",
    "\tprint('concat:',messages_concat_df.shape)\n",
    "\tmetadata_df_i = metadata_df_i.merge(messages_concat_df, on='conversation_id', how='left', suffixes=('', ''))\n",
    "\t# drop if nan on message\n",
    "\tprint(metadata_df_i.shape) \n",
    "\tmetadata_df_i = metadata_df_i[metadata_df_i['message'].notna()]\n",
    "\tprint(metadata_df_i.shape) \n",
    "\t\n",
    "\tdfs[split] = metadata_df_i.copy()\n",
    "\t\t\n",
    "\n",
    "\t\t\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, split in enumerate(['train', 'val', 'test']):\n",
    "\tmetadata_df_i = dfs[split]\n",
    "\tmetadata_df_i.to_csv(dataset_dir + f'{sub_dir}/{set_names[i]}_messages_texter_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concept_tracker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
